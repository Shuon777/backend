import json
import logging
import os
import time
from pathlib import Path
from urllib.parse import unquote

import redis
from flask import Flask, jsonify, request
from flask_cors import CORS
from http.client import HTTPException
from shapely.geometry import shape

from core.coordinates_finder import GeoProcessor
from core.relational_service import RelationalService
from core.search_service import SearchService
from embedding_config import embedding_config
from infrastructure.db_utils_for_search import Slot_validator
from infrastructure.geo_db_store import find_place_flexible, get_place
from infrastructure.maps_store import get_map_links
from infrastructure.to_nomn import find_place_key, to_prepositional_phrase
from utils import (
    generate_cache_key, 
    get_cached_result, 
    set_cached_result,
    clear_cache_pattern,
    get_cache_stats,
    init_redis
)

matplotlib_logger = logging.getLogger('matplotlib')
matplotlib_logger.setLevel(logging.WARNING)

app = Flask(__name__)
CORS(app)

MAPS_DIR = os.getenv("MAPS_DIR","/var/www/map_bot/maps")
DOMAIN = os.getenv("","https://testecobot.ru")
geo = GeoProcessor(maps_dir=MAPS_DIR, domain=DOMAIN)
slot_val = Slot_validator()
init_redis(host='localhost', port=6379, db=1, decode_responses=True)

current_model, current_model_path = embedding_config.get_active_model()
embedding_model_path = current_model_path

species_synonyms_path = os.getenv("SPECIES_SYNONYMS_PATH", 
                                 str(Path(__file__).parent / "json_files" / "species_synonyms.json"))

search_service = SearchService(
    embedding_model_path=embedding_model_path,
    species_synonyms_path=species_synonyms_path
)
relational_service = RelationalService(species_synonyms_path=species_synonyms_path)

user_locations = {}

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)
matplotlib_logger = logging.getLogger('matplotlib')
matplotlib_logger.setLevel(logging.WARNING)
    
@app.route("/objects_in_polygon_simply", methods=["POST"])
def objects_in_polygon_simply():
    debug_mode = request.args.get("debug_mode", "false").lower() == "true"
    in_stoplist = request.args.get("in_stoplist", "1")
    logger.info(f"üì¶ /objects_in_polygon_simply - GET params: {dict(request.args)}")
    logger.info(f"üì¶ /objects_in_polygon_simply - POST data: {request.get_json()}")

    data = request.get_json()
    name = data.get("name")
    buffer_radius_km = data.get("buffer_radius_km", 0)
    object_type = data.get("object_type")
    limit = data.get("limit", 20)

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∫–µ—à–∞
    cache_params = {
        "name": name,
        "buffer_radius_km": buffer_radius_km,
        "object_type": object_type,
        "limit": limit,
        "in_stoplist": in_stoplist,
        "version": "v2"
    }
    
    redis_key = f"cache:polygon_simply:{generate_cache_key(cache_params)}"
    debug_info = {
        "timestamp": time.time(),
        "cache_key": redis_key,
        "steps": []
    }

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
    cache_hit, cached_result = get_cached_result(redis_key, debug_info)
    if cache_hit:
        if debug_mode:
            cached_result["debug"] = debug_info
        return jsonify(cached_result)

    # Debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö
    debug_info["parameters"] = {
        "name": name,
        "buffer_radius_km": buffer_radius_km,
        "object_type": object_type,
        "limit": limit,
        "in_stoplist": in_stoplist
    }
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏–Ω–æ–Ω–∏–º—ã –ø–µ—Ä–µ–¥ –ø–æ–∏—Å–∫–æ–º –≥–µ–æ–º–µ—Ç—Ä–∏–∏
    try:
        # –ü–æ–ª—É—á–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ —Å–∏–Ω–æ–Ω–∏–º–æ–≤
        synonyms_data = search_service.get_synonyms_for_name(name)
        
        # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã —Å–∏–Ω–æ–Ω–∏–º—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Å–Ω–æ–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
        if "error" not in synonyms_data:
            main_names = list(synonyms_data.keys())
            if main_names:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤–æ–µ –æ—Å–Ω–æ–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
                canonical_name = main_names[0]
                logger.debug(f"–ù–∞–π–¥–µ–Ω —Å–∏–Ω–æ–Ω–∏–º: '{name}' -> '{canonical_name}'")
                name = canonical_name
                debug_info["steps"].append({
                    "step": "synonym_resolution",
                    "original_name": data.get("name"),
                    "canonical_name": canonical_name,
                    "synonyms_data": synonyms_data
                })
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –¥–ª—è '{name}': {e}")
        debug_info["steps"].append({
            "step": "synonym_resolution",
            "error": str(e)
        })
        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º
    
    entry = get_place(name)
    if not entry or "geometry" not in entry:
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ –æ—Å–Ω–æ–≤–Ω–æ–º—É –Ω–∞–∑–≤–∞–Ω–∏—é, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —á–µ—Ä–µ–∑ –≥–∏–±–∫–∏–π –ø–æ–∏—Å–∫
        flexible_result = find_place_flexible(name)
        if flexible_result and flexible_result.get("status") == "found":
            entry = flexible_result["record"]
            logger.debug(f"–ù–∞–π–¥–µ–Ω–æ —á–µ—Ä–µ–∑ –≥–∏–±–∫–∏–π –ø–æ–∏—Å–∫: '{name}' -> '{flexible_result['name']}'")
            debug_info["steps"].append({
                "step": "flexible_search",
                "found_name": flexible_result['name'],
                "original_name": name
            })
        else:
            response = {"error": f"–ì–µ–æ–º–µ—Ç—Ä–∏—è –¥–ª—è '{name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"}
            if debug_mode:
                response["debug"] = debug_info
            return jsonify(response), 404
    
    polygon = entry["geometry"]
    debug_info["geometry_source"] = {
        "source": "database" if entry else "flexible_search",
        "entry_id": entry.get("id", "unknown") if entry else "unknown"
    }

    if not polygon:
        response = {"error": "Polygon not specified"}
        if debug_mode:
            response["debug"] = debug_info
        return jsonify(response), 400
    
    try:
        results = search_service.get_objects_in_polygon(
            polygon_geojson=polygon,
            buffer_radius_km=float(buffer_radius_km),
            object_type=object_type,
            limit=int(limit)
        )
        objects = results.get("objects", [])
        answer = results.get("answer", "")
        
        # –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ü–û STOPLIST –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
        safe_objects = []
        stoplisted_objects = []
        
        for obj in objects:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º feature_data –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ in_stoplist
            feature_data = obj.get("features", {})
            obj_in_stoplist = feature_data.get("in_stoplist")
            
            try:
                requested_level = int(in_stoplist)
                if obj_in_stoplist is None or int(obj_in_stoplist) <= requested_level:
                    safe_objects.append(obj)
                else:
                    stoplisted_objects.append(obj)
                    logger.info(f"–ò—Å–∫–ª—é—á–µ–Ω –æ–±—ä–µ–∫—Ç —Å in_stoplist={obj_in_stoplist}: {obj.get('name', '–ë–µ–∑ –∏–º–µ–Ω–∏')}")
            except (ValueError, TypeError):
                if obj_in_stoplist is None or int(obj_in_stoplist) <= 1:
                    safe_objects.append(obj)
                else:
                    stoplisted_objects.append(obj)
                    logger.info(f"–ò—Å–∫–ª—é—á–µ–Ω –æ–±—ä–µ–∫—Ç —Å in_stoplist={obj_in_stoplist}: {obj.get('name', '–ë–µ–∑ –∏–º–µ–Ω–∏')}")
        
        objects = safe_objects
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç —Å —É—á–µ—Ç–æ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        if stoplisted_objects:
            answer = f"{answer} (–∏—Å–∫–ª—é—á–µ–Ω–æ {len(stoplisted_objects)} –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ —É—Ä–æ–≤–Ω—é –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏)"
        
        # Debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –ø–æ–∏—Å–∫–∞
        debug_info["search_results"] = {
            "total_objects": len(objects),
            "object_types": {},
            "polygon_area": "calculated" if polygon else "unknown"
        }
        
        # Debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ stoplist
        debug_info["stoplist_filter"] = {
            "total_before_filter": len(results.get("objects", [])),
            "safe_after_filter": len(objects),
            "stoplisted_count": len(stoplisted_objects)
        }
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –æ–±—ä–µ–∫—Ç–æ–≤
        for obj in objects:
            obj_type = obj.get("type", "unknown")
            if obj_type not in debug_info["search_results"]["object_types"]:
                debug_info["search_results"]["object_types"][obj_type] = 0
            debug_info["search_results"]["object_types"][obj_type] += 1
            
            # –î–æ–±–∞–≤–ª—è–µ–º ID –æ–±—ä–µ–∫—Ç–æ–≤ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            if "id" in obj:
                if "object_ids" not in debug_info["search_results"]:
                    debug_info["search_results"]["object_ids"] = {}
                if obj_type not in debug_info["search_results"]["object_ids"]:
                    debug_info["search_results"]["object_ids"][obj_type] = []
                debug_info["search_results"]["object_ids"][obj_type].append(obj["id"])
                
    except ValueError:
        response = {"error": "Invalid parameters format"}
        if debug_mode:
            response["debug"] = debug_info
        return jsonify(response), 400
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –ø–æ–ª–∏–≥–æ–Ω–µ: {e}")
        debug_info["search_error"] = str(e)
        response = {"error": "–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ"}
        if debug_mode:
            response["debug"] = debug_info
        return jsonify(response), 500

    if not objects:
        response = {
            "status": "no_objects", 
            "message": answer,
            "used_objects": [],
            "not_used_objects": []
        }
        if debug_mode:
            response["debug"] = debug_info
            response["in_stoplist_filter_applied"] = True
            response["in_stoplist_level"] = in_stoplist
        return jsonify(response)

    # –°–æ–±–∏—Ä–∞–µ–º –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∏–º–µ–Ω –¥–ª—è –æ—Ç–≤–µ—Ç–∞
    all_biological_names = sorted(list(set(
        obj.get('name', '–ë–µ–∑ –∏–º–µ–Ω–∏') 
        for obj in objects if obj.get('type') == 'biological_entity'
    )))

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –æ–±—ä–µ–∫—Ç—ã –ø–æ –≥–µ–æ–º–µ—Ç—Ä–∏–∏
    grouped_by_geojson = {}
    for obj in objects:
        if 'geojson' not in obj or not obj['geojson']:
            continue
        geojson_key = json.dumps(obj['geojson'], sort_keys=True)
        if geojson_key not in grouped_by_geojson:
            grouped_by_geojson[geojson_key] = {
                'geojson': obj['geojson'],
                'names': []
            }
        object_name = obj.get('name', '–ë–µ–∑ –∏–º–µ–Ω–∏')
        if object_name not in grouped_by_geojson[geojson_key]['names']:
             grouped_by_geojson[geojson_key]['names'].append(object_name)

    # Debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–µ
    debug_info["grouping"] = {
        "total_groups": len(grouped_by_geojson),
        "objects_per_group": [len(group['names']) for group in grouped_by_geojson.values()]
    }

    # --- –ù–û–í–ê–Ø –õ–û–ì–ò–ö–ê –§–û–†–ú–ò–†–û–í–ê–ù–ò–Ø –¢–ï–ö–°–¢–ê ---
    objects_for_map = []
    MAX_NAMES_IN_TOOLTIP = 3  # –ú–∞–∫—Å–∏–º—É–º –∏–º–µ–Ω –¥–ª—è –∫—Ä–∞—Ç–∫–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è

    # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–±—ä–µ–∫—Ç–∞—Ö –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞
    used_objects = []  # –û–±—ä–µ–∫—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –Ω–∞ –∫–∞—Ä—Ç–µ
    not_used_objects = []  # –û–±—ä–µ–∫—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –ø–æ–ø–∞–ª–∏ –Ω–∞ –∫–∞—Ä—Ç—É

    for group_data in grouped_by_geojson.values():
        names = sorted(group_data['names'])
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—ä–µ–∫—Ç—ã –≤ used_objects
        for name in names:
            used_objects.append({
                "name": name,
                "type": "biological_entity"  # –í —ç—Ç–æ–º —ç–Ω–¥–ø–æ–∏–Ω—Ç–µ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º biological_entity
            })
        
        # 1. –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Ç–∫–∏–π —Ç–µ–∫—Å—Ç –¥–ª—è Tooltip (–ø—Ä–∏ –Ω–∞–≤–µ–¥–µ–Ω–∏–∏)
        if len(names) > MAX_NAMES_IN_TOOLTIP:
            tooltip_text = f"{', '.join(names[:MAX_NAMES_IN_TOOLTIP])} –∏ –µ—â–µ {len(names) - MAX_NAMES_IN_TOOLTIP}..."
        else:
            tooltip_text = ", ".join(names)

        # 2. –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Å–∏–≤—ã–π HTML –¥–ª—è Popup (–ø—Ä–∏ –∫–ª–∏–∫–µ)
        popup_html = f"<h6>–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –≤–∏–¥–æ–≤: {len(names)}</h6>"
        popup_html += '<ul style="padding-left: 20px; margin-top: 5px;">'
        for n in names:
            popup_html += f"<li>{n}</li>"
        popup_html += "</ul>"
        
        objects_for_map.append({
            'tooltip': tooltip_text,
            'popup': popup_html,
            'geojson': group_data['geojson']
        })

    # –í —ç—Ç–æ–º —ç–Ω–¥–ø–æ–∏–Ω—Ç–µ –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å used_objects,
    # —Ç–∞–∫ –∫–∞–∫ –º—ã –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –∏—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –∫–∞—Ä—Ç–µ
    # not_used_objects –æ—Å—Ç–∞–≤–ª—è–µ–º –ø—É—Å—Ç—ã–º

    try:
        # –°–æ–∑–¥–∞–µ–º –∫–∞—Ä—Ç—É —Å –∏–º–µ–Ω–µ–º –∏–∑ redis_key (–∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–º—è)
        map_name = redis_key.replace("cache:", "map_").replace(":", "_")
        map_result = geo.draw_custom_geometries(objects_for_map, map_name)
        
        map_result["count"] = len(objects_for_map)
        map_result["answer"] = answer
        # –í 'grouped_names' —Ç–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫—Ä–∞—Ç–∫–∏–µ –∏–º–µ–Ω–∞ –¥–ª—è tooltip
        map_result["grouped_names"] = [obj.get("tooltip", "") for obj in objects_for_map]
        map_result["all_biological_names"] = all_biological_names
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–±—ä–µ–∫—Ç–∞—Ö –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞
        map_result["used_objects"] = used_objects
        map_result["not_used_objects"] = not_used_objects
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ stoplist
        map_result["in_stoplist_filter_applied"] = True
        map_result["in_stoplist_level"] = in_stoplist
        map_result["stoplisted_count"] = len(stoplisted_objects) if 'stoplisted_objects' in locals() else 0
        
        # –î–æ–±–∞–≤–ª—è–µ–º debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        if debug_mode:
            debug_info["visualization"] = {
                "map_name": map_name,
                "objects_count": len(objects_for_map),
                "biological_names_count": len(all_biological_names)
            }
            map_result["debug"] = debug_info

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–µ—à (45 –º–∏–Ω—É—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –ø–æ–ª–∏–≥–æ–Ω—É)
        set_cached_result(redis_key, map_result, expire_time=2700)
        
        return jsonify(map_result)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ –∫–∞—Ä—Ç—ã: {e}", exc_info=True)
        debug_info["visualization_error"] = str(e)
        response = {
            "status": "error", 
            "message": f"–û—à–∏–±–∫–∞ –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ –∫–∞—Ä—Ç—ã: {e}",
            "used_objects": [],
            "not_used_objects": []
        }
        if debug_mode:
            response["debug"] = debug_info
            response["in_stoplist_filter_applied"] = True
            response["in_stoplist_level"] = in_stoplist
        return jsonify(response), 500
        
@app.route("/objects_in_area_by_type", methods=["POST"])
def objects_in_area_by_type():
    data = request.get_json()
    debug_mode = request.args.get("debug_mode", "false").lower() == "true"

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∫–µ—à–∞
    cache_params = {
        "area_name": data.get("area_name"),
        "object_type": data.get("object_type", "all"),
        "object_subtype": data.get("object_subtype"),
        "object_name": data.get("object_name"),
        "limit": data.get("limit", 20),
        "search_around": data.get("search_around", False),
        "buffer_radius_km": data.get("buffer_radius_km", 10.0),
        "version": "v2"
    }
    
    redis_key = f"cache:area_search:{generate_cache_key(cache_params)}"
    debug_info = {
        "timestamp": time.time(),
        "cache_key": redis_key,
        "steps": []
    }

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
    cache_hit, cached_result = get_cached_result(redis_key, debug_info)
    if cache_hit:
        if debug_mode:
            cached_result["debug"] = debug_info
        return jsonify(cached_result)

    logger.info(f"üì¶ /objects_in_area_by_type - GET params: {dict(request.args)}")
    logger.info(f"üì¶ /objects_in_area_by_type - POST data: {request.get_json()}")

    area_name = data.get("area_name")
    object_type = data.get("object_type", "all") 
    object_subtype = data.get("object_subtype")
    object_name = data.get("object_name")
    limit = data.get("limit", 20)
    search_around = data.get("search_around", False)
    buffer_radius_km = data.get("buffer_radius_km", 10.0)

    debug_info["parameters"] = {
        "area_name": area_name,
        "object_type": object_type,
        "object_subtype": object_subtype,
        "object_name": object_name,
        "limit": limit,
        "search_around": search_around,
        "buffer_radius_km": buffer_radius_km
    }
    resolved_object_info = None
    if object_name:
        resolved_object_info = search_service.resolve_object_synonym(object_name, object_type)
        
        debug_info["synonym_resolution"] = {
            "original_name": object_name,
            "original_type": object_type,
            "resolved_info": resolved_object_info
        }
        
        if resolved_object_info.get("resolved", False):
            object_name = resolved_object_info["main_form"]
            if object_type != "all":
                object_type = resolved_object_info["object_type"]
            logger.info(f"‚úÖ –†–∞–∑—Ä–µ—à–µ–Ω —Å–∏–Ω–æ–Ω–∏–º –æ–±—ä–µ–∫—Ç–∞: '{resolved_object_info['original_name']}' -> '{object_name}' (—Ç–∏–ø: {object_type})")
        else:
            logger.info(f"‚ÑπÔ∏è –°–∏–Ω–æ–Ω–∏–º –¥–ª—è –æ–±—ä–µ–∫—Ç–∞ '{object_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ")
    
    def extract_external_id(feature_data):
        """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è ID –∏–∑ feature_data"""
        if not feature_data or not isinstance(feature_data, dict):
            return None

        meta_info = feature_data.get('meta_info', {})
        if isinstance(meta_info, dict):
            return meta_info.get('id')
        
        return None
    
    if not area_name and object_name:
        debug_info["steps"].append({
            "step": "direct_object_search",
            "reason": "area_name not provided, searching object directly",
            "resolved_name": object_name,
            "resolved_type": object_type
        })
        
        try:
            results = search_service.search_objects_directly_by_name(
                object_name=object_name,
                object_type=object_type,
                object_subtype=object_subtype,
                limit=limit
            )
            
            objects = results.get("objects", [])
            answer = results.get("answer", "")
            
            debug_info["search_results"] = {
                "total_objects_found": len(objects),
                "search_type": "direct_object_search"
            }
            
            if not objects:
                response = {
                    "status": "no_objects", 
                    "message": answer
                }
                if debug_mode:
                    response["debug"] = debug_info
                return jsonify(response)
            
            objects_for_map = []
            used_objects = []
            
            for obj in objects:
                name = obj.get('name', '–ë–µ–∑ –∏–º–µ–Ω–∏')
                description = obj.get('description', '')
                geojson = obj.get('geojson', {})
                obj_type = obj.get('type', 'unknown')
                
                # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—ä–µ–∫—Ç –≤ used_objects
                used_objects.append({
                    "name": name,
                    "type": obj_type,
                    "external_id": extract_external_id(obj.get('features', {})),
                    "geometry_type": obj.get('geometry_type')
                })
                
                popup_html = f"<h6>{name}</h6>"
                if obj_type:
                    popup_html += f"<p><strong>–¢–∏–ø:</strong> {obj_type}</p>"
                if description:
                    short_desc = description[:200] + "..." if len(description) > 200 else description
                    popup_html += f"<p>{short_desc}</p>"
                
                objects_for_map.append({
                    'tooltip': name,
                    'popup': popup_html,
                    'geojson': geojson
                })
            
            # –°–æ–∑–¥–∞–µ–º –∫–∞—Ä—Ç—É —Å –∏–º–µ–Ω–µ–º –∏–∑ redis_key (–∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–º—è)
            map_name = redis_key.replace("cache:", "map_").replace(":", "_")
            map_result = geo.draw_custom_geometries(objects_for_map, map_name)
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å external_id (—Ç–æ–ª—å–∫–æ –≤ –¥–∞–Ω–Ω—ã—Ö)
            detailed_objects = []
            for obj in objects:
                features = obj.get('features', {})
                external_id = extract_external_id(features)
                
                detailed_objects.append({
                    "name": obj.get('name'), 
                    "description": obj.get('description'),
                    "type": obj.get('type'),
                    "external_id": external_id,
                    "geometry_type": obj.get('geometry_type'),
                    "primary_types": obj.get('primary_types', []),
                    "specific_types": obj.get('specific_types', [])
                })
            
            map_result["count"] = len(objects)
            map_result["answer"] = answer
            map_result["objects"] = detailed_objects
            
            # –î–û–ë–ê–í–õ–Ø–ï–ú used_objects –∏ not_used_objects –ö –°–£–©–ï–°–¢–í–£–Æ–©–ï–ô –°–¢–†–£–ö–¢–£–†–ï
            map_result["used_objects"] = used_objects
            map_result["not_used_objects"] = []  # –í –ø—Ä—è–º–æ–º –ø–æ–∏—Å–∫–µ –≤—Å–µ –æ–±—ä–µ–∫—Ç—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–∏ —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –≤ –æ—Ç–≤–µ—Ç
            if resolved_object_info and resolved_object_info.get("resolved", False):
                map_result["synonym_resolution"] = {
                    "original_name": resolved_object_info["original_name"],
                    "resolved_name": object_name,
                    "original_type": resolved_object_info.get("original_type", object_type)
                }
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ external_id (—Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
            objects_with_external_id = [obj for obj in detailed_objects if obj.get('external_id')]
            if debug_mode and objects_with_external_id:
                debug_info["external_id_stats"] = {
                    "total_objects": len(detailed_objects),
                    "with_external_id": len(objects_with_external_id)
                }
            
            # –î–æ–±–∞–≤–ª—è–µ–º debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            if debug_mode:
                debug_info["visualization"] = {
                    "map_name": map_name,
                    "total_objects_on_map": len(objects_for_map),
                    "search_type": "direct_object_search"
                }
                map_result["debug"] = debug_info

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–µ—à (30 –º–∏–Ω—É—Ç –¥–ª—è –ø—Ä—è–º–æ–≥–æ –ø–æ–∏—Å–∫–∞)
            set_cached_result(redis_key, map_result, expire_time=1800)
            
            return jsonify(map_result)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä—è–º–æ–≥–æ –ø–æ–∏—Å–∫–∞ –æ–±—ä–µ–∫—Ç–∞: {str(e)}")
            debug_info["error"] = str(e)
            response = {"error": "–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –æ–±—ä–µ–∫—Ç–∞"}
            if debug_mode:
                response["debug"] = debug_info
            return jsonify(response), 500
    
    # –°–¢–ê–†–ê–Ø –õ–û–ì–ò–ö–ê: –ü–æ–∏—Å–∫ –ø–æ –æ–±–ª–∞—Å—Ç–∏ (–µ—Å–ª–∏ area_name —É–∫–∞–∑–∞–Ω)
    if not area_name:
        response = {"error": "area_name is required when no object_name provided"}
        if debug_mode:
            response["debug"] = debug_info
        return jsonify(response), 400
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º relational_service –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ–ª–∏–≥–æ–Ω–∞ –æ–±–ª–∞—Å—Ç–∏
    area_geometry = None
    area_info = None
    
    try:
        # –ò—â–µ–º –ø–æ–ª–∏–≥–æ–Ω –æ–±–ª–∞—Å—Ç–∏ —á–µ—Ä–µ–∑ relational_service
        area_results = relational_service.find_area_geometry(area_name)
        
        if area_results:
            area_geometry = area_results.get("geometry")
            area_info = area_results.get("area_info", {})
            
            debug_info["steps"].append({
                "step": "area_search",
                "found": True,
                "area_title": area_info.get('title', area_name),
                "source": area_info.get('source', 'unknown')
            })
        else:
            debug_info["steps"].append({
                "step": "area_search", 
                "found": False,
                "error": "Area not found in map_content"
            })
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –æ–±–ª–∞—Å—Ç–∏ —á–µ—Ä–µ–∑ relational_service: {str(e)}")
        debug_info["steps"].append({
            "step": "area_search",
            "error": str(e)
        })
    
    if not area_geometry:
        response = {"error": f"–ü–æ–ª–∏–≥–æ–Ω –¥–ª—è –æ–±–ª–∞—Å—Ç–∏ '{area_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"}
        if debug_mode:
            response["debug"] = debug_info
        return jsonify(response), 404

    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º search_service –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ–±—ä–µ–∫—Ç–æ–≤ —Å –Ω–æ–≤—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–µ –∏–º—è –∏ —Ç–∏–ø)
        results = search_service.get_objects_in_area_by_type(
            area_geometry=area_geometry,
            object_type=object_type,
            object_subtype=object_subtype,
            object_name=object_name,
            limit=int(limit),
            search_around=search_around,
            buffer_radius_km=float(buffer_radius_km)
        )
        
        objects = results.get("objects", [])
        answer = results.get("answer", "")
        search_stats = results.get("search_stats", {})
        
        # Debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
        debug_info["search_results"] = {
            "total_objects_found": len(objects),
            "search_criteria": {
                "object_type": object_type,
                "object_subtype": object_subtype,
                "object_name": object_name,
                "search_around": search_around,
                "buffer_radius_km": buffer_radius_km
            },
            "location_stats": search_stats
        }
        
        if not objects:
            response = {
                "status": "no_objects", 
                "message": answer
            }
            if debug_mode:
                response["debug"] = debug_info
            return jsonify(response)
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –æ–±—ä–µ–∫—Ç—ã –¥–ª—è –∫–∞—Ä—Ç—ã –∏ —Å–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–±—ä–µ–∫—Ç–∞—Ö
        objects_for_map = []
        used_objects = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–∏–≥–æ–Ω –æ–±–ª–∞—Å—Ç–∏ –∫–∞–∫ –ø–µ—Ä–≤—ã–π –æ–±—ä–µ–∫—Ç
        area_title = area_info.get('title', area_name) if area_info else area_name
        objects_for_map.append({
            'tooltip': f"–û–±–ª–∞—Å—Ç—å –ø–æ–∏—Å–∫–∞: {area_title}",
            'popup': f"<h6>{area_title}</h6><p>–û–±–ª–∞—Å—Ç—å –ø–æ–∏—Å–∫–∞</p>",
            'geojson': area_geometry
        })
        
        # –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω –ø–æ–∏—Å–∫ –≤–æ–∫—Ä—É–≥, –¥–æ–±–∞–≤–ª—è–µ–º –±—É—Ñ–µ—Ä–Ω—É—é –∑–æ–Ω—É
        buffer_geometry = None
        if search_around:
            # –°–æ–∑–¥–∞–µ–º –±—É—Ñ–µ—Ä–Ω—É—é –∑–æ–Ω—É –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ geo_service
            buffer_geometry = search_service.geo_service.create_buffer_geometry(area_geometry, buffer_radius_km)
            if buffer_geometry:
                objects_for_map.append({
                    'tooltip': f"–ó–æ–Ω–∞ –ø–æ–∏—Å–∫–∞ (+{buffer_radius_km} –∫–º)",
                    'popup': f"<h6>–ó–æ–Ω–∞ –ø–æ–∏—Å–∫–∞</h6><p>–ë—É—Ñ–µ—Ä–Ω–∞—è –∑–æ–Ω–∞ {buffer_radius_km} –∫–º –≤–æ–∫—Ä—É–≥ –æ–±–ª–∞—Å—Ç–∏</p>",
                    'geojson': buffer_geometry,
                    'style': {'color': 'orange', 'fillOpacity': 0.1, 'weight': 2}
                })
                debug_info["steps"].append({
                    "step": "buffer_zone_creation",
                    "success": True,
                    "buffer_radius_km": buffer_radius_km
                })
            else:
                debug_info["steps"].append({
                    "step": "buffer_zone_creation", 
                    "success": False,
                    "error": "Failed to create buffer geometry"
                })
        
        for obj in objects:
            name = obj.get('name', '–ë–µ–∑ –∏–º–µ–Ω–∏')
            description = obj.get('description', '')
            geojson = obj.get('geojson', {})
            location_type = obj.get('location_type', 'inside')
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—ä–µ–∫—Ç –≤ used_objects
            used_objects.append({
                "name": name,
                "type": obj.get('type', 'unknown'),
                "external_id": extract_external_id(obj.get('features', {})),
                "geometry_type": obj.get('geometry_type'),
                "location_type": location_type
            })
            
            popup_html = f"<h6>{name}</h6>"
            if description:
                short_desc = description[:200] + "..." if len(description) > 200 else description
                popup_html += f"<p>{short_desc}</p>"
            
            objects_for_map.append({
                'tooltip': name,
                'popup': popup_html,
                'geojson': geojson
            })
        
        # –°–æ–∑–¥–∞–µ–º –∫–∞—Ä—Ç—É —Å –∏–º–µ–Ω–µ–º –∏–∑ redis_key (–∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–º—è)
        map_name = redis_key.replace("cache:", "map_").replace(":", "_")
        map_result = geo.draw_custom_geometries(objects_for_map, map_name)
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–±—ä–µ–∫—Ç–∞—Ö
        detailed_objects = []
        for obj in objects:
            features = obj.get('features', {})
            external_id = extract_external_id(features)
            
            detailed_objects.append({
                "name": obj.get('name'), 
                "description": obj.get('description'),
                "type": obj.get('type'),
                "external_id": external_id,
                "geometry_type": obj.get('geometry_type'),
                "primary_types": obj.get('primary_types', []),
                "specific_types": obj.get('specific_types', []),
                "location_type": obj.get('location_type', 'inside')
            })
        
        map_result["count"] = len(objects)
        map_result["answer"] = answer
        map_result["objects"] = detailed_objects
        map_result["search_stats"] = search_stats
        
        # –î–û–ë–ê–í–õ–Ø–ï–ú used_objects –∏ not_used_objects –ö –°–£–©–ï–°–¢–í–£–Æ–©–ï–ô –°–¢–†–£–ö–¢–£–†–ï
        map_result["used_objects"] = used_objects
        map_result["not_used_objects"] = []  # –í —ç—Ç–æ–º —ç–Ω–¥–ø–æ–∏–Ω—Ç–µ –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±—É—Ñ–µ—Ä–Ω–æ–π –∑–æ–Ω–µ –≤ –æ—Ç–≤–µ—Ç
        if buffer_geometry:
            map_result["buffer_zone"] = {
                "radius_km": buffer_radius_km,
                "geometry": buffer_geometry
            }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–∏ —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –≤ –æ—Ç–≤–µ—Ç
        if resolved_object_info and resolved_object_info.get("resolved", False):
            map_result["synonym_resolution"] = {
                "original_name": resolved_object_info["original_name"],
                "resolved_name": object_name,
                "original_type": resolved_object_info.get("original_type", object_type)
            }
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ external_id (—Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
        objects_with_external_id = [obj for obj in detailed_objects if obj.get('external_id')]
        if debug_mode and objects_with_external_id:
            debug_info["external_id_stats"] = {
                "total_objects": len(detailed_objects),
                "with_external_id": len(objects_with_external_id)
            }
        
        # –î–æ–±–∞–≤–ª—è–µ–º debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        if debug_mode:
            debug_info["visualization"] = {
                "map_name": map_name,
                "total_objects_on_map": len(objects_for_map),
                "area_included": True,
                "buffer_zone_included": search_around and buffer_geometry is not None,
                "objects_inside": search_stats.get('inside_area', 0),
                "objects_around": search_stats.get('around_area', 0)
            }
            map_result["debug"] = debug_info

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–µ—à (1 —á–∞—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –æ–±–ª–∞—Å—Ç–∏)
        set_cached_result(redis_key, map_result, expire_time=3600)
        
        return jsonify(map_result)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ —Ç–∏–ø—É –≤ –æ–±–ª–∞—Å—Ç–∏: {str(e)}")
        debug_info["error"] = str(e)
        response = {"error": "–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ"}
        if debug_mode:
            response["debug"] = debug_info
        return jsonify(response), 500
           
def validate_geojson_polygon(geojson: dict) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ GeoJSON —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∞–ª–∏–¥–Ω—ã–π –ø–æ–ª–∏–≥–æ–Ω"""
    try:
        if geojson.get("type") != "Polygon":
            return False
            
        coordinates = geojson.get("coordinates")
        if not coordinates or not isinstance(coordinates, list):
            return False
            
        for ring in coordinates:
            if len(ring) < 4 or ring[0] != ring[-1]:
                return False
                
        return True
    except:
        return False
    
@app.route("/search_images_by_features", methods=["POST"])
def search_images_by_features():
    """
    –ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º –∏–∑ feature_data
    –ú–æ–∂–Ω–æ –∏—Å–∫–∞—Ç—å –∫–∞–∫ –ø–æ –≤–∏–¥—É, —Ç–∞–∫ –∏ —Ç–æ–ª—å–∫–æ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º
    """
    debug_mode = request.args.get("debug_mode", "false").lower() == "true"
    in_stoplist = request.args.get("in_stoplist", "1")  # –ù–æ–≤—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä
    
    debug_info = {
        "timestamp": time.time(),
        "steps": []
    }
    
    try:
        data = request.get_json()
        species_name = data.get("species_name")
        features = data.get("features", {})
        if "fruits_present" not in features:
            features["fruits_present"] = "–Ω–µ—Ç"
            
        if not species_name and not features:
            response = {
                "error": "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å species_name –∏–ª–∏ features",
                "used_objects": [],
                "not_used_objects": []
            }
            return jsonify(response), 400
        
        logger.info(f"üîç /search_images_by_features - –ø–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏:")
        logger.info(f"   - species_name: {data.get('species_name')}")
        logger.info(f"   - features: {data.get('features', {})}")
        logger.info(f"   - query_params: debug_mode={debug_mode}, in_stoplist={in_stoplist}")
        logger.info(f"   - raw_data: {data}")
        
        # Debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–ø—Ä–æ—Å–µ
        debug_info["parameters"] = {
            "species_name": species_name,
            "features": features,
            "in_stoplist": in_stoplist,
            "timestamp": time.time()
        }
        
        if species_name:
            result = search_service.search_images_by_features(
                species_name=species_name,
                features=features
            )
            
            # –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ü–û STOPLIST –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            if result.get("status") == "success" and "images" in result:
                safe_images = []
                stoplisted_images = []
                
                for image in result["images"]:
                    feature_data = image.get("features", {})
                    image_in_stoplist = feature_data.get("in_stoplist")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Ä–æ–≤–µ–Ω—å –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
                    try:
                        requested_level = int(in_stoplist)
                        if image_in_stoplist is None or int(image_in_stoplist) <= requested_level:
                            safe_images.append(image)
                        else:
                            stoplisted_images.append(image)
                            logger.info(f"–ò—Å–∫–ª—é—á–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å in_stoplist={image_in_stoplist}: {image.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}")
                    except (ValueError, TypeError):
                        # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º —É—Ä–æ–≤–µ–Ω—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (1)
                        if image_in_stoplist is None or int(image_in_stoplist) <= 1:
                            safe_images.append(image)
                        else:
                            stoplisted_images.append(image)
                            logger.info(f"–ò—Å–∫–ª—é—á–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å in_stoplist={image_in_stoplist}: {image.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}")
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
                result["images"] = safe_images
                result["count"] = len(safe_images)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
                result["in_stoplist_filter_applied"] = True
                result["in_stoplist_level"] = in_stoplist
                result["stoplisted_count"] = len(stoplisted_images)
            
            # ============================================================================
            # –§–û–†–ú–ò–†–û–í–ê–ù–ò–ï used_objects –ò not_used_objects –î–õ–Ø –ü–û–ò–°–ö–ê –ü–û –í–ò–î–£
            # ============================================================================
            used_objects = []      # –û–±—ä–µ–∫—Ç—ã, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
            not_used_objects = []  # –û–±—ä–µ–∫—Ç—ã, –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏—è–º (–≤ —ç—Ç–æ–º —ç–Ω–¥–ø–æ–∏–Ω—Ç–µ –≤—Å–µ–≥–¥–∞ –ø—É—Å—Ç–æ)
            
            if result.get("status") == "success" and result.get("images"):
                # –î–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –≤–∏–¥—É - used_objects —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –≤–∏–¥
                used_objects.append({
                    "name": species_name,
                    "type": "biological_entity",
                    "images_count": len(result["images"])
                })
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—ä–µ–∫—Ç—ã –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result["used_objects"] = used_objects
            result["not_used_objects"] = not_used_objects
            
            # –î–æ–±–∞–≤–ª—è–µ–º debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            if debug_mode:
                debug_info["search_type"] = "with_species"
                debug_info["synonyms_used"] = result.get("synonyms_used", {})
                debug_info["database_query"] = {
                    "species_conditions": result.get("species_conditions", []),
                    "feature_conditions": list(features.keys())
                }
                debug_info["stoplist_filter"] = {
                    "total_before_filter": len(result.get("images", [])),
                    "safe_after_filter": len(safe_images) if species_name else "N/A",
                    "stoplisted_count": len(stoplisted_images) if species_name else "N/A"
                }
                result["debug"] = debug_info
                
            if result.get("status") == "not_found":
                # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—ã–µ –æ–±—ä–µ–∫—Ç—ã –¥–ª—è —Å–ª—É—á–∞—è "–Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
                result["used_objects"] = []
                result["not_used_objects"] = []
                return jsonify(result), 404
            return jsonify(result)
        
        else:
            # –ü–æ–∏—Å–∫ —Ç–æ–ª—å–∫–æ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º (–±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è –≤–∏–¥–∞)
            result = search_service.relational_service.search_images_by_features_only(
                features=features
            )
            
            # –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ü–û STOPLIST –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (—Ç–æ–ª—å–∫–æ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º)
            if result.get("status") == "success" and "images" in result:
                safe_images = []
                stoplisted_images = []
                
                for image in result["images"]:
                    feature_data = image.get("features", {})
                    image_in_stoplist = feature_data.get("in_stoplist")
                    
                    try:
                        requested_level = int(in_stoplist)
                        if image_in_stoplist is None or int(image_in_stoplist) <= requested_level:
                            safe_images.append(image)
                        else:
                            stoplisted_images.append(image)
                            logger.info(f"–ò—Å–∫–ª—é—á–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å in_stoplist={image_in_stoplist}: {image.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}")
                    except (ValueError, TypeError):
                        if image_in_stoplist is None or int(image_in_stoplist) <= 1:
                            safe_images.append(image)
                        else:
                            stoplisted_images.append(image)
                            logger.info(f"–ò—Å–∫–ª—é—á–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å in_stoplist={image_in_stoplist}: {image.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}")
                
                result["images"] = safe_images
                result["count"] = len(safe_images)
                result["in_stoplist_filter_applied"] = True
                result["in_stoplist_level"] = in_stoplist
                result["stoplisted_count"] = len(stoplisted_images)
            
            # ============================================================================
            # –§–û–†–ú–ò–†–û–í–ê–ù–ò–ï used_objects –ò not_used_objects –î–õ–Ø –ü–û–ò–°–ö–ê –¢–û–õ–¨–ö–û –ü–û –ü–†–ò–ó–ù–ê–ö–ê–ú
            # ============================================================================
            used_objects = []      # –í–∏–¥—ã, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
            not_used_objects = []  # –í—Å–µ–≥–¥–∞ –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤
            
            if result.get("status") == "success" and result.get("images"):
                # –°–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –≤–∏–¥—ã –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                unique_species = {}
                for image in result["images"]:
                    species = image.get("species_name")
                    if species and species not in unique_species:
                        unique_species[species] = {
                            "name": species,
                            "type": "biological_entity",
                            "images_count": 0
                        }
                    if species:
                        unique_species[species]["images_count"] += 1
                
                used_objects = list(unique_species.values())
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—ä–µ–∫—Ç—ã –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result["used_objects"] = used_objects
            result["not_used_objects"] = not_used_objects
            
            # –î–æ–±–∞–≤–ª—è–µ–º debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            if debug_mode:
                debug_info["search_type"] = "features_only"
                debug_info["database_query"] = {
                    "feature_conditions": list(features.keys())
                }
                debug_info["stoplist_filter"] = {
                    "total_before_filter": len(result.get("images", [])),
                    "safe_after_filter": len(safe_images),
                    "stoplisted_count": len(stoplisted_images)
                }
                result["debug"] = debug_info
                
            if result.get("status") == "not_found":
                # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—ã–µ –æ–±—ä–µ–∫—Ç—ã –¥–ª—è —Å–ª—É—á–∞—è "–Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
                result["used_objects"] = []
                result["not_used_objects"] = []
                return jsonify(result), 404
            return jsonify(result)
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º: {str(e)}")
        error_response = {
            "status": "error",
            "message": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {str(e)}",
            "used_objects": [],
            "not_used_objects": []
        }
        if debug_mode:
            debug_info["error"] = str(e)
            error_response["debug"] = debug_info
        return jsonify(error_response), 500
    
@app.route("/object/description/", methods=["GET", "POST"])
def get_object_description():
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ GET –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    logger.info(f"üì¶ /object/description - GET params: {dict(request.args)}")
    logger.info(f"üì¶ /object/description - POST data: {request.get_json()}")
    
    object_name = request.args.get("object_name")
    query = request.args.get("query")
    limit = int(request.args.get("limit", 0))
    similarity_threshold = float(request.args.get("similarity_threshold", 0.01))
    include_similarity = request.args.get("include_similarity", "false").lower() == "true"
    use_gigachat_filter = request.args.get("use_gigachat_filter", "false").lower() == "true"
    use_gigachat_answer = request.args.get("use_gigachat_answer", "false").lower() == "true"
    debug_mode = request.args.get("debug_mode", "false").lower() == "true"
    object_type = request.args.get("object_type", "all")
    save_prompt = request.args.get("save_prompt", "false").lower() == "true"
    in_stoplist = request.args.get("in_stoplist", "1")

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ POST body
    filter_data = None
    if request.method == "POST" and request.is_json:
        filter_data = request.get_json()
        logger.debug(f"–ü–æ–ª—É—á–µ–Ω—ã —Ñ–∏–ª—å—Ç—Ä—ã –∏–∑ body: {filter_data}")

    # Debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    debug_info = {
        "parameters": {
            "object_name": object_name,
            "object_type": object_type,
            "query": query,
            "limit": limit,
            "similarity_threshold": similarity_threshold,
            "include_similarity": include_similarity,
            "use_gigachat_filter": use_gigachat_filter,
            "use_gigachat_answer": use_gigachat_answer,
            "filter_data": filter_data,
            "save_prompt": save_prompt,
            "in_stoplist": in_stoplist
        },
        "timestamp": time.time(),
        "steps": []
    }

    # –†–ê–ó–†–ï–®–ï–ù–ò–ï –°–ò–ù–û–ù–ò–ú–û–í –û–ë–™–ï–ö–¢–û–í
    resolved_object_info = None
    if object_name:
        resolved_object_info = search_service.resolve_object_synonym(object_name, object_type)
        
        debug_info["synonym_resolution"] = {
            "original_name": object_name,
            "original_type": object_type,
            "resolved_info": resolved_object_info
        }
        
        if resolved_object_info.get("resolved", False):
            object_name = resolved_object_info["main_form"]
            # –ù–µ –º–µ–Ω—è–µ–º object_type, –µ—Å–ª–∏ –æ–Ω –Ω–µ –±—ã–ª –ø–µ—Ä–µ–¥–∞–Ω –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ
            if object_type != "all":
                object_type = resolved_object_info["object_type"]
            logger.info(f"‚úÖ –†–∞–∑—Ä–µ—à–µ–Ω —Å–∏–Ω–æ–Ω–∏–º –æ–±—ä–µ–∫—Ç–∞: '{resolved_object_info['original_name']}' -> '{object_name}' (—Ç–∏–ø: {object_type})")
        else:
            logger.info(f"‚ÑπÔ∏è –°–∏–Ω–æ–Ω–∏–º –¥–ª—è –æ–±—ä–µ–∫—Ç–∞ '{object_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ")

    # –í–ê–ñ–ù–û: –ï—Å–ª–∏ use_gigachat_answer=True, —Ç–æ query –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω
    if use_gigachat_answer and not query:
        response = {"error": "–ü–∞—Ä–∞–º–µ—Ç—Ä 'query' –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –ø—Ä–∏ use_gigachat_answer=true"}
        if debug_mode:
            response["debug"] = debug_info
        return jsonify(response), 400

    # –ï—Å–ª–∏ –Ω–µ—Ç –Ω–∏ object_name, –Ω–∏ query, –Ω–∏ filter_data - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É
    if not object_name and not query and not filter_data:
        response = {"error": "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å object_name, query –∏–ª–∏ –ø–µ—Ä–µ–¥–∞—Ç—å —Ñ–∏–ª—å—Ç—Ä—ã –≤ body"}
        if debug_mode:
            response["debug"] = debug_info
        return jsonify(response), 400

    # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è external_id
    def extract_external_id(desc_data):
        """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è external_id –∏–∑ –¥–∞–Ω–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏—è"""
        if not desc_data or not isinstance(desc_data, dict):
            return None
        
        # –û—Å–Ω–æ–≤–Ω–æ–π –ø—É—Ç—å: structured_data -> metadata -> meta_info -> id
        if 'structured_data' in desc_data and isinstance(desc_data['structured_data'], dict):
            structured_data = desc_data['structured_data']
            
            if ('metadata' in structured_data and 
                isinstance(structured_data['metadata'], dict) and
                'meta_info' in structured_data['metadata'] and
                isinstance(structured_data['metadata']['meta_info'], dict)):
                
                meta_info = structured_data['metadata']['meta_info']
                external_id = meta_info.get('id')
                
                if external_id:
                    return str(external_id)
        
        return None

    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ª–∏–º–∏—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
        search_limit = limit if limit > 0 else 100
        context_limit = 5
        
        if filter_data:
            descriptions = search_service.get_object_descriptions_by_filters(
                filter_data=filter_data,
                object_type=object_type,
                limit=search_limit,
                in_stoplist=in_stoplist,
                object_name=object_name  # –ü–µ—Ä–µ–¥–∞–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
            )
            search_method = "filter_search"
            
        elif query:
            embedding = search_service.embedding_model.embed_query(query)
            
            if not isinstance(embedding, list):
                logger.error(f"Embedding –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º, –ø–æ–ª—É—á–µ–Ω: {type(embedding)}")
                return jsonify({"error": "Internal embedding error"}), 500
                
            if not all(isinstance(x, (int, float)) for x in embedding):
                logger.error("Embedding —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ—á–∏—Å–ª–æ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã")
                return jsonify({"error": "Internal embedding error"}), 500
                
            if object_name:
                descriptions = search_service.get_object_descriptions_with_embedding(
                    object_name=object_name,
                    object_type=object_type,
                    query_embedding=embedding,
                    limit=search_limit,
                    similarity_threshold=similarity_threshold,
                    in_stoplist=in_stoplist
                )
                search_method = "object_with_embedding"
            else:
                descriptions = search_service.search_objects_by_embedding(
                    query_embedding=embedding,
                    object_type=object_type,
                    limit=search_limit,
                    similarity_threshold=similarity_threshold,
                    in_stoplist=in_stoplist
                )
                search_method = "semantic_search"
                
        else:
            descriptions_text = search_service.get_object_descriptions(
                object_name, 
                object_type,
                in_stoplist=in_stoplist
            )
            
            if include_similarity:
                descriptions = [{"content": text, "similarity": None, "source": "content"} 
                              for text in descriptions_text]
            else:
                descriptions = [{"content": text, "source": "content"} 
                              for text in descriptions_text]
            search_method = "simple_search"

        # Debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –ø–æ–∏—Å–∫–∞
        if debug_mode:
            debug_info["search_method"] = search_method
            debug_info["search_results"] = {
                "total_found": len(descriptions),
                "search_limit": search_limit,
                "similarities": [desc.get("similarity", 0) for desc in descriptions] if descriptions and search_method != "simple_search" else []
            }

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –∑–∞–ø–∏—Å–∏ (—Å –ø–æ–¥—Ö–æ–¥—è—â–∏–º in_stoplist)
        safe_descriptions = []
        stoplisted_descriptions = []

        for desc in descriptions:
            if isinstance(desc, dict):
                feature_data = desc.get("feature_data", {})
                desc_in_stoplist = feature_data.get("in_stoplist") if feature_data else None
                
                try:
                    requested_level = int(in_stoplist)
                    if desc_in_stoplist is None or int(desc_in_stoplist) <= requested_level:
                        safe_descriptions.append(desc)
                    else:
                        stoplisted_descriptions.append(desc)
                except (ValueError, TypeError):
                    if desc_in_stoplist is None or int(desc_in_stoplist) <= 1:
                        safe_descriptions.append(desc)
                    else:
                        stoplisted_descriptions.append(desc)
            else:
                safe_descriptions.append(desc)
                
        if debug_mode and descriptions:
            debug_info["sample_description_structure"] = []
            for i, desc in enumerate(descriptions[:2]):
                if isinstance(desc, dict):
                    sample_structure = {
                        "index": i,
                        "keys": list(desc.keys()),
                        "has_feature_data": 'feature_data' in desc,
                        "has_structured_data": 'structured_data' in desc
                    }
                    if 'feature_data' in desc and isinstance(desc['feature_data'], dict):
                        sample_structure["feature_data_keys"] = list(desc['feature_data'].keys())
                        if 'metadata' in desc['feature_data'] and isinstance(desc['feature_data']['metadata'], dict):
                            sample_structure["metadata_keys"] = list(desc['feature_data']['metadata'].keys())
                    debug_info["sample_description_structure"].append(sample_structure)
        
        # Debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ in_stoplist
        if debug_mode:
            debug_info["in_stoplist_filter"] = {
                "total_before_filter": len(descriptions),
                "safe_after_filter": len(safe_descriptions),
                "stoplisted_count": len(stoplisted_descriptions),
                "requested_level": in_stoplist
            }

        # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        if not safe_descriptions:
            response = {"error": "–Ø –Ω–µ –≥–æ—Ç–æ–≤ –ø—Ä–æ —ç—Ç–æ —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞—Ç—å"}
            if debug_mode:
                response["debug"] = debug_info
            return jsonify(response), 400

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        descriptions = safe_descriptions

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ use_gigachat_filter
        if use_gigachat_filter:
            filter_query = query if query else object_name
            
            if debug_mode:
                debug_info["before_gigachat_filter"] = {
                    "count": len(descriptions),
                    "filter_query": filter_query
                }
            
            filtered_descriptions = search_service.filter_text_descriptions_with_gigachat(
                filter_query, 
                descriptions
            )
            
            if debug_mode:
                debug_info["after_gigachat_filter"] = {
                    "count": len(filtered_descriptions),
                    "filtered_out": len(descriptions) - len(filtered_descriptions)
                }

            descriptions = filtered_descriptions

        # ============================================================================
        # –§–û–†–ú–ò–†–û–í–ê–ù–ò–ï used_objects –ò not_used_objects –î–õ–Ø –†–ê–ó–ù–´–• –°–¶–ï–ù–ê–†–ò–ï–í
        # ============================================================================
        
        used_objects = []      # –û–±—ä–µ–∫—Ç—ã, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ GigaChat
        not_used_objects = []  # –û–±—ä–µ–∫—Ç—ã, –Ω–µ –≤–æ—à–µ–¥—à–∏–µ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç GigaChat

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ use_gigachat_answer
        if use_gigachat_answer:
            if not descriptions:
                response = {"error": "–ù–µ –Ω–∞–π–¥–µ–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–π –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞"}
                if debug_mode:
                    response["debug"] = debug_info
                return jsonify(response), 404

            # –§–ò–õ–¨–¢–†–ê–¶–ò–Ø BLACKLIST_RISK
            safe_descriptions_for_gigachat = []
            blacklisted_descriptions = []
            
            for desc in descriptions:
                if isinstance(desc, dict):
                    feature_data = desc.get("feature_data", {})
                    if feature_data and feature_data.get("blacklist_risk") is True:
                        blacklisted_descriptions.append(desc)
                        continue
                    
                    if desc.get("blacklist_risk") is True:
                        blacklisted_descriptions.append(desc)
                        continue
                
                safe_descriptions_for_gigachat.append(desc)
            
            # Debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ blacklist
            if debug_mode:
                debug_info["blacklist_filter"] = {
                    "total_before_filter": len(descriptions),
                    "safe_after_filter": len(safe_descriptions_for_gigachat),
                    "blacklisted_count": len(blacklisted_descriptions)
                }
            
            # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            if not safe_descriptions_for_gigachat:
                response = {"error": "–í—Å–µ –æ–ø–∏—Å–∞–Ω–∏—è —Å–æ–¥–µ—Ä–∂–∞—Ç —Ä–∏—Å–∫ blacklist –∏ –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ GigaChat"}
                if debug_mode:
                    response["debug"] = debug_info
                return jsonify(response), 400

            descriptions_for_context = safe_descriptions_for_gigachat

            # –ë–µ—Ä–µ–º —Ç–æ–ø –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            if all('similarity' in desc for desc in descriptions_for_context):
                context_descriptions = sorted(descriptions_for_context, key=lambda x: x.get('similarity', 0), reverse=True)[:context_limit]
            else:
                context_descriptions = descriptions_for_context[:context_limit]
            
            # ============================================================================
            # –§–û–†–ú–ò–†–û–í–ê–ù–ò–ï –°–ü–ò–°–ö–û–í –û–ë–™–ï–ö–¢–û–í –î–õ–Ø –°–¶–ï–ù–ê–†–ò–Ø –° GIGACHAT
            # ============================================================================
            
            # used_objects - –æ–±—ä–µ–∫—Ç—ã –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ GigaChat (—Ç–æ–ø –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏)
            for desc in context_descriptions:
                if isinstance(desc, dict):
                    obj_info = {
                        "name": desc.get("object_name", object_name if object_name else "semantic_search"),
                        "type": desc.get("object_type", object_type),
                        "source": desc.get("source", "unknown"),
                        "similarity": round(desc.get("similarity", 0), 4) if desc.get("similarity") else None
                    }
                    used_objects.append(obj_info)
            
            # not_used_objects - –æ–±—ä–µ–∫—Ç—ã, –Ω–µ –≤–æ—à–µ–¥—à–∏–µ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç GigaChat
            remaining_descriptions = [desc for desc in descriptions_for_context if desc not in context_descriptions]
            for desc in remaining_descriptions:
                if isinstance(desc, dict):
                    obj_info = {
                        "name": desc.get("object_name", object_name if object_name else "semantic_search"),
                        "type": desc.get("object_type", object_type),
                        "source": desc.get("source", "unknown"),
                        "similarity": round(desc.get("similarity", 0), 4) if desc.get("similarity") else None
                    }
                    not_used_objects.append(obj_info)
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–æ–ø –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
            context = "\n\n".join([
                desc["content"] if isinstance(desc, dict) else desc 
                for desc in context_descriptions
            ])

            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
            total_count = len(descriptions_for_context)
            count_info = f"\n\n–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π: {total_count}"
            if len(blacklisted_descriptions) > 0:
                count_info += f" (–∏—Å–∫–ª—é—á–µ–Ω–æ {len(blacklisted_descriptions)} –∑–∞–ø–∏—Å–µ–π —Å —Ä–∏—Å–∫–æ–º blacklist)"
            if total_count > context_limit:
                count_info += f" (–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–∫–ª—é—á–µ–Ω–æ —Ç–æ–ø-{context_limit} –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏)"
            
            context += count_info
            
            # –°–û–•–†–ê–ù–ï–ù–ò–ï –ü–û–õ–ù–û–ì–û –ü–†–û–ú–ü–¢–ê
            full_prompt = f"""–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ë–∞–π–∫–∞–ª—å—Å–∫–æ–π –ø—Ä–∏—Ä–æ–¥–Ω–æ–π —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∏. 
–ò—Å–ø–æ–ª—å–∑—É–π —Ç–≤–æ—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –¥–ª—è —Ç–æ—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

–û—Å–æ–±—ã–µ —É–∫–∞–∑–∞–Ω–∏—è:
- –ù–∞ –≤–æ–ø—Ä–æ—Å—ã '—Å–∫–æ–ª—å–∫–æ' - –ø–æ–¥—Å—á–∏—Ç–∞–π –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
–ù–∞–ø—Ä–∏–º–µ—Ä, –Ω–∞ –≤–æ–ø—Ä–æ—Å '–°–∫–æ–ª—å–∫–æ –º—É–∑–µ–µ–≤?' –ø—Ä–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ '–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: 98 (–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–∫–ª—é—á–µ–Ω–æ —Ç–æ–ø-5 –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏)', –Ω—É–∂–Ω–æ –æ—Ç–≤–µ—Ç–∏—Ç—å –æ–∫–æ–ª–æ 98 –º—É–∑–µ–µ–≤ –∏ –∑–∞—Ç–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –º—É–∑–µ—è –∏–∑ —Ç–æ–ø –∑–∞–ø–∏—Å–µ–π
- –ë—É–¥—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º –∏ –ª–∞–∫–æ–Ω–∏—á–Ω—ã–º
- –î–∞–∂–µ –ø—Ä–∏ –Ω–µ–ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–µ—Ç–∞–ª–∏

–¢–≤–æ—è –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π:
{context}

–í–æ–ø—Ä–æ—Å: {query}

–û—Ç–≤–µ—Ç:"""
            
            if save_prompt:
                current_dir = Path(__file__).parent
                timestamp = int(time.time())
                prompt_filename = current_dir / f"gigachat_prompt_{timestamp}.txt"
                
                try:
                    with open(prompt_filename, 'w', encoding='utf-8') as f:
                        f.write(full_prompt)
                    logger.info(f"‚úÖ –ü–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {prompt_filename}")
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ–º–ø—Ç–∞: {e}")
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å –ø–æ–º–æ—â—å—é GigaChat
            try:
                gigachat_result = search_service._generate_gigachat_answer(query, context)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª –ª–∏ –æ—Ç–≤–µ—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω
                is_blacklist = gigachat_result.get("finish_reason") == "blacklist" or not gigachat_result.get("success", True)
                
                # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è
                if is_blacklist:
                    logger.info("üö´ GigaChat –≤–µ—Ä–Ω—É–ª blacklist, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è")
                    
                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è
                    formatted_descriptions = []
                    for i, desc in enumerate(descriptions_for_context, 1):
                        if isinstance(desc, dict):
                            content = desc.get("content", "")
                            similarity = desc.get("similarity")
                            source = desc.get("source", "unknown")
                            
                            # –ò–ó–í–õ–ï–ö–ê–ï–ú EXTERNAL_ID (—Ç–æ–ª—å–∫–æ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö)
                            external_id = extract_external_id(desc)
                            
                            formatted_desc = {
                                "id": i,
                                "content": content,
                                "source": source,
                                "feature_data": desc.get("feature_data", {}),
                                "structured_data": desc.get("structured_data", {})
                            }
                            
                            # –î–û–ë–ê–í–õ–Ø–ï–ú EXTERNAL_ID –í –î–ê–ù–ù–´–ï
                            if external_id:
                                formatted_desc["external_id"] = external_id
                            
                            if similarity is not None:
                                formatted_desc["similarity"] = round(similarity, 4)
                                
                            lines = content.strip().split('\n')
                            if lines and lines[0].strip():
                                formatted_desc["title"] = lines[0].strip()[:100]
                            else:
                                formatted_desc["title"] = f"–û–ø–∏—Å–∞–Ω–∏–µ {i}"
                                
                            formatted_descriptions.append(formatted_desc)
                        else:
                            formatted_descriptions.append({
                                "id": i,
                                "title": f"–û–ø–∏—Å–∞–Ω–∏–µ {i}",
                                "content": desc,
                                "source": "content"
                            })

                    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ similarity –µ—Å–ª–∏ –µ—Å—Ç—å
                    if all('similarity' in desc for desc in formatted_descriptions):
                        formatted_descriptions.sort(key=lambda x: x.get('similarity', 0), reverse=True)

                    response_data = {
                        "count": len(formatted_descriptions),
                        "descriptions": formatted_descriptions,
                        "query_used": query if query else "simple_search",
                        "similarity_threshold": similarity_threshold if query else None,
                        "use_gigachat_filter": use_gigachat_filter,
                        "use_gigachat_answer": True,
                        "gigachat_restricted": True,
                        "message": "GigaChat –Ω–µ —Å–º–æ–≥ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç, –ø–æ—ç—Ç–æ–º—É –≤–æ–∑–≤—Ä–∞—â–µ–Ω—ã –∏—Å—Ö–æ–¥–Ω—ã–µ –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è",
                        "formatted": True,
                        "in_stoplist_filter_applied": True,
                        "in_stoplist_level": in_stoplist,
                        # –î–û–ë–ê–í–õ–Ø–ï–ú –û–ë–™–ï–ö–¢–´
                        "used_objects": used_objects,
                        "not_used_objects": not_used_objects
                    }

                    if object_name:
                        response_data["object_name"] = object_name
                        response_data["object_type"] = object_type

                    if filter_data:
                        response_data["filters_applied"] = filter_data

                    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–∏ —Å–∏–Ω–æ–Ω–∏–º–æ–≤
                    if resolved_object_info and resolved_object_info.get("resolved", False):
                        response_data["synonym_resolution"] = {
                            "original_name": resolved_object_info["original_name"],
                            "resolved_name": object_name,
                            "original_type": resolved_object_info.get("original_type", object_type)
                        }

                    if debug_mode:
                        response_data["debug"] = debug_info
                        response_data["debug"]["gigachat_generation"] = {
                            "finish_reason": gigachat_result.get("finish_reason"),
                            "blacklist_detected": True,
                            "fallback_to_descriptions": True,
                            "prompt_saved": save_prompt
                        }

                    return jsonify(response_data)
                
                # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –Ω–µ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—ã—á–Ω—ã–π –æ—Ç–≤–µ—Ç GigaChat
                gigachat_response = gigachat_result.get("content", "")

                # –°–û–ë–ò–†–ê–ï–ú EXTERNAL_ID –ò–ó –ö–û–ù–¢–ï–ö–°–¢–ù–´–• –û–ü–ò–°–ê–ù–ò–ô
                external_ids = []
                source_descriptions_summary = []

                for desc in context_descriptions:
                    if isinstance(desc, dict):
                        # –ò–ó–í–õ–ï–ö–ê–ï–ú EXTERNAL_ID
                        external_id = extract_external_id(desc)
                        
                        desc_summary = {
                            "content_preview": desc.get("content", "")[:200] + "..." if len(desc.get("content", "")) > 200 else desc.get("content", ""),
                            "source": desc.get("source", "unknown"),
                            "similarity": round(desc.get("similarity", 0), 4) if desc.get("similarity") else None
                        }
                        
                        if external_id:
                            desc_summary["external_id"] = external_id
                            if external_id not in external_ids:
                                external_ids.append(external_id)
                                
                        source_descriptions_summary.append(desc_summary)

                response_data = {
                    "gigachat_answer": gigachat_response,
                    "external_ids": external_ids,  # –°–ü–ò–°–û–ö –í–°–ï–• EXTERNAL_ID
                    "source_descriptions": source_descriptions_summary,  # –ö–†–ê–¢–ö–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û–ë –ò–°–¢–û–ß–ù–ò–ö–ê–•
                    "context_used": {
                        "descriptions_count": len(context_descriptions),
                        "total_descriptions": total_count,
                        "blacklisted_excluded": len(blacklisted_descriptions),
                        "external_ids_count": len(external_ids)
                    },
                    "query": query,
                    "object_name": object_name if object_name else "semantic_search",
                    "object_type": object_type,
                    "in_stoplist_level": in_stoplist,
                    # –î–û–ë–ê–í–õ–Ø–ï–ú –û–ë–™–ï–ö–¢–´
                    "used_objects": used_objects,
                    "not_used_objects": not_used_objects
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–∏ —Å–∏–Ω–æ–Ω–∏–º–æ–≤
                if resolved_object_info and resolved_object_info.get("resolved", False):
                    response_data["synonym_resolution"] = {
                        "original_name": resolved_object_info["original_name"],
                        "resolved_name": object_name,
                        "original_type": resolved_object_info.get("original_type", object_type)
                    }
                
                if debug_mode:
                    response_data["debug"] = debug_info
                    response_data["debug"]["gigachat_generation"] = {
                        "response_length": len(gigachat_response),
                        "finish_reason": gigachat_result.get("finish_reason"),
                        "blacklist_detected": False,
                        "prompt_saved": save_prompt
                    }

                return jsonify(response_data)
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ GigaChat: {str(e)}")
                error_response = {"error": "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ GigaChat"}
                if debug_mode:
                    debug_info["gigachat_error"] = str(e)
                    error_response["debug"] = debug_info
                return jsonify(error_response), 500

        # ============================================================================
        # –§–û–†–ú–ò–†–û–í–ê–ù–ò–ï –°–ü–ò–°–ö–û–í –û–ë–™–ï–ö–¢–û–í –î–õ–Ø –°–¶–ï–ù–ê–†–ò–Ø –ë–ï–ó GIGACHAT
        # ============================================================================
        
        # –î–ª—è —Å—Ü–µ–Ω–∞—Ä–∏—è –±–µ–∑ GigaChat:
        # used_objects - –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã (—Ç–∞–∫ –∫–∞–∫ –æ–Ω–∏ –≤—Å–µ "–∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è" –≤ –æ—Ç–≤–µ—Ç–µ)
        # not_used_objects - –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤
        
        for desc in descriptions:
            if isinstance(desc, dict):
                obj_info = {
                    "name": desc.get("object_name", object_name if object_name else "semantic_search"),
                    "type": desc.get("object_type", object_type),
                    "source": desc.get("source", "unknown"),
                    "similarity": round(desc.get("similarity", 0), 4) if desc.get("similarity") else None
                }
                used_objects.append(obj_info)

        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –±–µ–∑ GigaChat
        if not descriptions:
            response = {"error": "–Ø –Ω–µ –≥–æ—Ç–æ–≤ –ø—Ä–æ —ç—Ç–æ —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞—Ç—å"}
            if debug_mode:
                response["debug"] = debug_info
            return jsonify(response), 404

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏—è
        formatted_descriptions = []
        for i, desc in enumerate(descriptions, 1):
            if isinstance(desc, dict):
                content = desc.get("content", "")
                similarity = desc.get("similarity")
                source = desc.get("source", "unknown")
                
                # –ò–ó–í–õ–ï–ö–ê–ï–ú EXTERNAL_ID (—Ç–æ–ª—å–∫–æ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö)
                external_id = extract_external_id(desc)
                
                formatted_desc = {
                    "id": i,
                    "content": content,
                    "source": source,
                    "feature_data": desc.get("feature_data", {}),
                    "structured_data": desc.get("structured_data", {})
                }
                
                # –î–û–ë–ê–í–õ–Ø–ï–ú EXTERNAL_ID –í –î–ê–ù–ù–´–ï
                if external_id:
                    formatted_desc["external_id"] = external_id
                
                if similarity is not None:
                    formatted_desc["similarity"] = round(similarity, 4)
                    
                lines = content.strip().split('\n')
                if lines and lines[0].strip():
                    formatted_desc["title"] = lines[0].strip()[:100]
                else:
                    formatted_desc["title"] = f"–û–ø–∏—Å–∞–Ω–∏–µ {i}"
                    
                formatted_descriptions.append(formatted_desc)
            else:
                formatted_descriptions.append({
                    "id": i,
                    "title": f"–û–ø–∏—Å–∞–Ω–∏–µ {i}",
                    "content": desc,
                    "source": "content"
                })

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ similarity –µ—Å–ª–∏ –µ—Å—Ç—å
        if all('similarity' in desc for desc in formatted_descriptions):
            formatted_descriptions.sort(key=lambda x: x.get('similarity', 0), reverse=True)

        response_data = {
            "count": len(formatted_descriptions),
            "descriptions": formatted_descriptions,
            "query_used": query if query else "simple_search",
            "similarity_threshold": similarity_threshold if query else None,
            "use_gigachat_filter": use_gigachat_filter,
            "in_stoplist_filter_applied": True,
            "in_stoplist_level": in_stoplist,
            "formatted": True,
            # –î–û–ë–ê–í–õ–Ø–ï–ú –û–ë–™–ï–ö–¢–´
            "used_objects": used_objects,
            "not_used_objects": []  # –í —Å—Ü–µ–Ω–∞—Ä–∏–∏ –±–µ–∑ GigaChat –≤—Å–µ –æ–±—ä–µ–∫—Ç—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è
        }

        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–±—ä–µ–∫—Ç–µ
        if object_name:
            response_data["object_name"] = object_name
            response_data["object_type"] = object_type

        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∏–ª—å—Ç—Ä–∞—Ö
        if filter_data:
            response_data["filters_applied"] = filter_data

        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–∏ —Å–∏–Ω–æ–Ω–∏–º–æ–≤
        if resolved_object_info and resolved_object_info.get("resolved", False):
            response_data["synonym_resolution"] = {
                "original_name": resolved_object_info["original_name"],
                "resolved_name": object_name,
                "original_type": resolved_object_info.get("original_type", object_type)
            }

        # –î–æ–±–∞–≤–ª—è–µ–º debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        if debug_mode:
            response_data["debug"] = debug_info

        return jsonify(response_data)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ–ø–∏—Å–∞–Ω–∏—è: {str(e)}", exc_info=True)
        error_response = {"error": "–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"}
        if debug_mode:
            debug_info["error"] = str(e)
            error_response["debug"] = debug_info
        return jsonify(error_response), 500
       
@app.route("/species/description/", methods=["GET"])
def get_species_description():
    species_name = request.args.get("species_name")
    query = request.args.get("query")
    limit = int(request.args.get("limit", 5))
    similarity_threshold = float(request.args.get("similarity_threshold", 0.5))
    include_similarity = request.args.get("include_similarity", "false").lower() == "true"
    use_gigachat_filter = request.args.get("use_gigachat_filter", "false").lower() == "true"
    debug_mode = request.args.get("debug_mode", "false").lower() == "true"
    in_stoplist = request.args.get("in_stoplist", "1")

    if not species_name:
        response = {
            "error": "species_name parameter is required",
            "used_objects": [],
            "not_used_objects": []
        }
        return jsonify(response), 400

    # Debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    debug_info = {
        "parameters": {
            "species_name": species_name,
            "query": query,
            "limit": limit,
            "similarity_threshold": similarity_threshold,
            "include_similarity": include_similarity,
            "use_gigachat_filter": use_gigachat_filter,
            "in_stoplist": in_stoplist
        },
        "timestamp": time.time()
    }

    try:
        if query:
            embedding = search_service.embedding_model.embed_query(query)
            
            if not isinstance(embedding, list):
                logger.error(f"Embedding –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º, –ø–æ–ª—É—á–µ–Ω: {type(embedding)}")
                return jsonify({"error": "Internal embedding error"}), 500
                
            if not all(isinstance(x, (int, float)) for x in embedding):
                logger.error("Embedding —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ—á–∏—Å–ª–æ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã")
                return jsonify({"error": "Internal embedding error"}), 500
                
            # Debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± embedding
            if debug_mode:
                debug_info["embedding"] = {
                    "type": type(embedding).__name__,
                    "length": len(embedding),
                    "first_5_elements": embedding[:5] if isinstance(embedding, list) else "N/A"
                }
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º relational_service –≤–º–µ—Å—Ç–æ search_service
            descriptions = search_service.relational_service.get_text_descriptions_with_embedding(
                species_name=species_name,
                query_embedding=embedding,
                limit=limit,
                similarity_threshold=similarity_threshold,
                in_stoplist=in_stoplist
            )
            
            # Debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –ø–æ–∏—Å–∫–∞
            if debug_mode:
                debug_info["search_method"] = "embedding_similarity"
                debug_info["search_results"] = {
                    "total_found": len(descriptions),
                    "similarities": [desc.get("similarity", 0) for desc in descriptions] if descriptions else []
                }
            
        else:
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º search_service.get_text_descriptions
            descriptions = search_service.get_text_descriptions(species_name, in_stoplist=in_stoplist)
            
            # Debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            if debug_mode:
                debug_info["search_method"] = "simple_search"
                debug_info["search_results"] = {
                    "total_found": len(descriptions)
                }
                
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –∑–∞–ø–∏—Å–∏ (—Å –ø–æ–¥—Ö–æ–¥—è—â–∏–º in_stoplist)
        safe_descriptions = []
        stoplisted_descriptions = []
        
        for desc in descriptions:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º feature_data –Ω–∞ –Ω–∞–ª–∏—á–∏–µ in_stoplist
            if isinstance(desc, dict):
                feature_data = desc.get("feature_data", {})
                desc_in_stoplist = feature_data.get("in_stoplist") if feature_data else None
                
                # –ï—Å–ª–∏ in_stoplist –Ω–µ —É–∫–∞–∑–∞–Ω –∏–ª–∏ <= –∑–∞–ø—Ä–æ—à–µ–Ω–Ω–æ–º—É —É—Ä–æ–≤–Ω—é, —Å—á–∏—Ç–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–º
                try:
                    requested_level = int(in_stoplist)
                    if desc_in_stoplist is None or int(desc_in_stoplist) <= requested_level:
                        safe_descriptions.append(desc)
                    else:
                        stoplisted_descriptions.append(desc)
                        logger.info(f"–ò—Å–∫–ª—é—á–µ–Ω –¥–æ–∫—É–º–µ–Ω—Ç —Å in_stoplist={desc_in_stoplist} (–∑–∞–ø—Ä–æ—à–µ–Ω —É—Ä–æ–≤–µ–Ω—å {requested_level}): {species_name}")
                except (ValueError, TypeError):
                    # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º —É—Ä–æ–≤–µ–Ω—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (1)
                    if desc_in_stoplist is None or int(desc_in_stoplist) <= 1:
                        safe_descriptions.append(desc)
                    else:
                        stoplisted_descriptions.append(desc)
                        logger.info(f"–ò—Å–∫–ª—é—á–µ–Ω –¥–æ–∫—É–º–µ–Ω—Ç —Å in_stoplist={desc_in_stoplist}: {species_name}")
            else:
                # –î–ª—è –ø—Ä–æ—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ —Å—á–∏—Ç–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–º–∏
                safe_descriptions.append(desc)

        # Debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ in_stoplist
        if debug_mode:
            debug_info["in_stoplist_filter"] = {
                "total_before_filter": len(descriptions),
                "safe_after_filter": len(safe_descriptions),
                "stoplisted_count": len(stoplisted_descriptions),
                "requested_level": in_stoplist
            }

        # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        if not safe_descriptions:
            response = {
                "error": "–Ø –Ω–µ –≥–æ—Ç–æ–≤ –ø—Ä–æ —ç—Ç–æ —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞—Ç—å",
                "used_objects": [],
                "not_used_objects": []
            }
            if debug_mode:
                response["debug"] = debug_info
            return jsonify(response), 400

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        descriptions = safe_descriptions

        # ============================================================================
        # –§–û–†–ú–ò–†–û–í–ê–ù–ò–ï used_objects –ò not_used_objects
        # ============================================================================
        used_objects = []      # –í—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã (–≤ —ç—Ç–æ–º —ç–Ω–¥–ø–æ–∏–Ω—Ç–µ –≤—Å–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è)
        not_used_objects = []  # –ü—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤ (–≤—Å–µ –æ–±—ä–µ–∫—Ç—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è)

        # –í —ç—Ç–æ–º —ç–Ω–¥–ø–æ–∏–Ω—Ç–µ used_objects —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–¥–µ
        for desc in descriptions:
            used_objects.append({
                "name": species_name,
                "type": "biological_entity",
                "source": desc.get("source", "unknown") if isinstance(desc, dict) else "content",
                "similarity": round(desc.get("similarity", 0), 4) if isinstance(desc, dict) and desc.get("similarity") else None
            })

        if use_gigachat_filter:
            filter_query = query if query else species_name
            
            logger.debug("–û–ø–∏—Å–∞–Ω–∏—è –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Å Gigachat")
            logger.debug(descriptions)
            
            # Debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            if debug_mode:
                debug_info["before_gigachat_filter"] = {
                    "count": len(descriptions),
                    "filter_query": filter_query
                }
            
            filtered_descriptions = search_service.filter_text_descriptions_with_gigachat(
                filter_query, 
                descriptions
            )
            
            # Debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            if debug_mode:
                debug_info["after_gigachat_filter"] = {
                    "count": len(filtered_descriptions),
                    "filtered_out": len(descriptions) - len(filtered_descriptions)
                }

            # –û–±–Ω–æ–≤–ª—è–µ–º used_objects –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ Gigachat
            if filtered_descriptions:
                used_objects = []
                for desc in filtered_descriptions:
                    used_objects.append({
                        "name": species_name,
                        "type": "biological_entity", 
                        "source": desc.get("source", "unknown") if isinstance(desc, dict) else "content",
                        "similarity": round(desc.get("similarity", 0), 4) if isinstance(desc, dict) and desc.get("similarity") else None
                    })

            descriptions = filtered_descriptions

        if not descriptions:
            response = {
                "error": "–Ø –Ω–µ –≥–æ—Ç–æ–≤ –ø—Ä–æ —ç—Ç–æ —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞—Ç—å",
                "used_objects": [],
                "not_used_objects": []
            }
            if debug_mode:
                response["debug"] = debug_info
            return jsonify(response), 404

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        if include_similarity:
            response_data = {
                "count": len(descriptions),
                "descriptions": descriptions,
                "query_used": query if query else "simple_search",
                "similarity_threshold": similarity_threshold if query else None,
                "use_gigachat_filter": use_gigachat_filter,
                "in_stoplist_filter_applied": True,
                "in_stoplist_level": in_stoplist,
                # –î–û–ë–ê–í–õ–Ø–ï–ú –û–ë–™–ï–ö–¢–´
                "used_objects": used_objects,
                "not_used_objects": not_used_objects
            }
        else:
            response_data = {
                "count": len(descriptions),
                "descriptions": [{"content": desc["content"] if isinstance(desc, dict) else desc,
                                "source": desc.get("source", "unknown") if isinstance(desc, dict) else "content",
                                "feature_data": desc.get("feature_data", {}) if isinstance(desc, dict) else {}} 
                               for desc in descriptions],
                "query_used": query if query else "simple_search",
                "similarity_threshold": similarity_threshold if query else None,
                "use_gigachat_filter": use_gigachat_filter,
                "in_stoplist_filter_applied": True,
                "in_stoplist_level": in_stoplist,
                # –î–û–ë–ê–í–õ–Ø–ï–ú –û–ë–™–ï–ö–¢–´
                "used_objects": used_objects,
                "not_used_objects": not_used_objects
            }

        # –î–æ–±–∞–≤–ª—è–µ–º debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        if debug_mode:
            response_data["debug"] = debug_info

        return jsonify(response_data)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è '{species_name}': {str(e)}", exc_info=True)
        error_response = {
            "error": "–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞",
            "used_objects": [],
            "not_used_objects": []
        }
        if debug_mode:
            debug_info["error"] = str(e)
            error_response["debug"] = debug_info
        return jsonify(error_response), 500

@app.route("/get_coords", methods=["POST"])
def api_get_coords():
    data = request.get_json()
    name = data.get("name")
    
    logger.info(f"üîç /get_coords - –ø–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å:")
    logger.info(f"   - name: {name}")
    logger.info(f"   - raw_data: {data}")
    
    if not name:
        return jsonify({
            "status": "error", 
            "message": "–ü–∞—Ä–∞–º–µ—Ç—Ä 'name' –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω.",
            "used_objects": [],
            "not_used_objects": []
        }), 400

    result = geo.get_point_coords_from_geodb(name)
    
    used_objects = []
    not_used_objects = []
    
    if result.get("status") == "ok":
        used_objects.append({
            "name": name,
            "type": "geographical_entity"
        })
    else:
        not_used_objects.append({
            "name": name, 
            "type": "geographical_entity"
        })
    
    # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –æ–±—ä–µ–∫—Ç–∞–º–∏
    result["used_objects"] = used_objects
    result["not_used_objects"] = not_used_objects
    
    return jsonify(result)

@app.route("/coords_to_map", methods=["POST"])
def api_coords_to_map():
    t0 = time.perf_counter()
    data = request.get_json()
    t_after_parse = time.perf_counter()
    lat = data.get("latitude")
    lon = data.get("longitude")
    radius = data.get("radius_km", 30)
    object_type = data.get("object_type")
    species_name = data.get("species_name")
    debug_mode = request.args.get("debug_mode", "false").lower() == "true"
    in_stoplist_param = request.args.get("in_stoplist", "1")
    try:
        if in_stoplist_param.lower() in ['false', 'true']:
            in_stoplist = 1
        else:
            in_stoplist = int(in_stoplist_param)
    except (ValueError, TypeError):
        in_stoplist = 1
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∫–µ—à–∞
    cache_params = {
        "latitude": lat,
        "longitude": lon,
        "radius_km": radius,
        "object_type": object_type,
        "species_name": species_name,
        "in_stoplist": in_stoplist,
        "version": "v2"
    }
    
    redis_key = f"cache:coords_search:{generate_cache_key(cache_params)}"
    debug_info = {
        "timestamp": time.time(),
        "cache_key": redis_key,
        "search_time": 0,
        "parse_time": round(t_after_parse - t0, 3)
    }

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
    cache_hit, cached_result = get_cached_result(redis_key, debug_info)
    if cache_hit:
        if debug_mode:
            cached_result["debug"] = debug_info
        return jsonify(cached_result)

    logger.debug(f"""–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:{data}""")
    if not lat or not lon:
        response = {
            "status": "error", 
            "message": "–ù–µ –∑–∞–¥–∞–Ω—ã –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã.",
            "used_objects": [],
            "not_used_objects": []
        }
        if debug_mode:
            response["debug"] = debug_info
        return jsonify(response), 400

    # Initialize t3 in case visualization fails
    t3 = time.perf_counter()
    
    try:
        t1 = time.perf_counter()
        result = search_service.get_nearby_objects(
            latitude=float(lat),
            longitude=float(lon),
            radius_km=float(radius),
            object_type=object_type,
            species_name=species_name,
            in_stoplist=in_stoplist
        )
        t2 = time.perf_counter()
        objects = result.get("objects", [])
        answer = result.get("answer", "")
        
        # Debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        debug_info["search_time"] = round(t2 - t1, 3)
        debug_info["parameters"] = {
            "latitude": lat,
            "longitude": lon,
            "radius_km": radius,
            "object_type": object_type,
            "species_name": species_name,
            "in_stoplist": in_stoplist
        }
        debug_info["objects_count"] = len(objects)
        debug_info["search_query_details"] = result.get("debug_info", {})
        
        if not objects:
            response = {
                "status": "no_objects", 
                "message": answer,
                "used_objects": [],
                "not_used_objects": []
            }
            if debug_mode:
                response["debug"] = debug_info
            return jsonify(response)

        # –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ü–û STOPLIST –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
        safe_objects = []
        stoplisted_objects = []
        
        for obj in objects:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º feature_data –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ in_stoplist
            feature_data = obj.get("features", {})
            obj_in_stoplist = feature_data.get("in_stoplist")
            
            try:
                requested_level = int(in_stoplist)
                if obj_in_stoplist is None or int(obj_in_stoplist) <= requested_level:
                    safe_objects.append(obj)
                else:
                    stoplisted_objects.append(obj)
                    logger.info(f"–ò—Å–∫–ª—é—á–µ–Ω –æ–±—ä–µ–∫—Ç —Å in_stoplist={obj_in_stoplist}: {obj.get('name', '–ë–µ–∑ –∏–º–µ–Ω–∏')}")
            except (ValueError, TypeError):
                if obj_in_stoplist is None or int(obj_in_stoplist) <= 1:
                    safe_objects.append(obj)
                else:
                    stoplisted_objects.append(obj)
                    logger.info(f"–ò—Å–∫–ª—é—á–µ–Ω –æ–±—ä–µ–∫—Ç —Å in_stoplist={obj_in_stoplist}: {obj.get('name', '–ë–µ–∑ –∏–º–µ–Ω–∏')}")
        
        objects = safe_objects
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç —Å —É—á–µ—Ç–æ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        if stoplisted_objects:
            answer = f"{answer} (–∏—Å–∫–ª—é—á–µ–Ω–æ {len(stoplisted_objects)} –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ —É—Ä–æ–≤–Ω—é –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏)"
        
        # Debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ stoplist
        debug_info["stoplist_filter"] = {
            "total_before_filter": len(result.get("objects", [])),
            "safe_after_filter": len(objects),
            "stoplisted_count": len(stoplisted_objects)
        }
        
        if not objects:
            response = {
                "status": "no_objects", 
                "message": answer,
                "used_objects": [],
                "not_used_objects": []
            }
            if debug_mode:
                response["debug"] = debug_info
                response["in_stoplist_filter_applied"] = True
                response["in_stoplist_level"] = in_stoplist
            return jsonify(response)

        # Filter out invalid geometries before visualization
        valid_objects = []
        object_details = []
        
        # ============================================================================
        # –§–û–†–ú–ò–†–û–í–ê–ù–ò–ï used_objects –ò not_used_objects
        # ============================================================================
        used_objects = []      # –û–±—ä–µ–∫—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –Ω–∞ –∫–∞—Ä—Ç–µ
        not_used_objects = []  # –û–±—ä–µ–∫—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –ø–æ–ø–∞–ª–∏ –Ω–∞ –∫–∞—Ä—Ç—É (–Ω–µ–≤–∞–ª–∏–¥–Ω–∞—è –≥–µ–æ–º–µ—Ç—Ä–∏—è)
        
        for obj in objects:
            try:
                if obj.get("geojson") and obj["geojson"].get("coordinates"):
                    # Basic validation of coordinates
                    if isinstance(obj["geojson"]["coordinates"][0], (int, float)):
                        lon, lat = obj["geojson"]["coordinates"]
                        if -180 <= lon <= 180 and -90 <= lat <= 90:
                            valid_objects.append(obj)
                            object_details.append({
                                "id": obj.get("id", "unknown"),
                                "name": obj.get("name", "–ë–µ–∑ –∏–º–µ–Ω–∏"),
                                "type": obj.get("type", "unknown"),
                                "distance_km": obj.get("distance", "unknown")
                            })
                            # –î–æ–±–∞–≤–ª—è–µ–º –≤ used_objects
                            used_objects.append({
                                "name": obj.get("name", "–ë–µ–∑ –∏–º–µ–Ω–∏"),
                                "type": obj.get("type", "unknown"),
                                "distance_km": obj.get("distance", "unknown"),
                                "geometry_type": "point"
                            })
                    elif isinstance(obj["geojson"]["coordinates"][0], list):
                        # For polygons/multipoints, check first coordinate
                        first_coord = obj["geojson"]["coordinates"][0][0]
                        if isinstance(first_coord, (int, float)):
                            if -180 <= first_coord <= 180:
                                valid_objects.append(obj)
                                object_details.append({
                                    "id": obj.get("id", "unknown"),
                                    "name": obj.get("name", "–ë–µ–∑ –∏–º–µ–Ω–∏"),
                                    "type": obj.get("type", "unknown"),
                                    "distance_km": obj.get("distance", "unknown")
                                })
                                # –î–æ–±–∞–≤–ª—è–µ–º –≤ used_objects
                                used_objects.append({
                                    "name": obj.get("name", "–ë–µ–∑ –∏–º–µ–Ω–∏"),
                                    "type": obj.get("type", "unknown"),
                                    "distance_km": obj.get("distance", "unknown"),
                                    "geometry_type": "polygon"
                                })
                        elif len(first_coord) >= 2:
                            lon, lat = first_coord[:2]
                            if -180 <= lon <= 180 and -90 <= lat <= 90:
                                valid_objects.append(obj)
                                object_details.append({
                                    "id": obj.get("id", "unknown"),
                                    "name": obj.get("name", "–ë–µ–∑ –∏–º–µ–Ω–∏"),
                                    "type": obj.get("type", "unknown"),
                                    "distance_km": obj.get("distance", "unknown")
                                })
                                # –î–æ–±–∞–≤–ª—è–µ–º –≤ used_objects
                                used_objects.append({
                                    "name": obj.get("name", "–ë–µ–∑ –∏–º–µ–Ω–∏"),
                                    "type": obj.get("type", "unknown"),
                                    "distance_km": obj.get("distance", "unknown"),
                                    "geometry_type": "complex"
                                })
                else:
                    # –û–±—ä–µ–∫—Ç –±–µ–∑ –≥–µ–æ–º–µ—Ç—Ä–∏–∏ - –¥–æ–±–∞–≤–ª—è–µ–º –≤ not_used_objects
                    not_used_objects.append({
                        "name": obj.get("name", "–ë–µ–∑ –∏–º–µ–Ω–∏"),
                        "type": obj.get("type", "unknown"),
                        "distance_km": obj.get("distance", "unknown"),
                        "reason": "no_geometry"
                    })
            except Exception as e:
                logger.warning(f"Invalid geometry in object {obj.get('name')}: {str(e)}")
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ not_used_objects —Å –ø—Ä–∏—á–∏–Ω–æ–π –æ—à–∏–±–∫–∏
                not_used_objects.append({
                    "name": obj.get("name", "–ë–µ–∑ –∏–º–µ–Ω–∏"),
                    "type": obj.get("type", "unknown"),
                    "distance_km": obj.get("distance", "unknown"),
                    "reason": "invalid_geometry",
                    "error": str(e)
                })
                continue

        debug_info["valid_objects_count"] = len(valid_objects)
        debug_info["object_details"] = object_details
        debug_info["validation_errors"] = len(objects) - len(valid_objects)

        if not valid_objects:
            response = {
                "status": "error",
                "message": "–ù–∞–π–¥–µ–Ω—ã –æ–±—ä–µ–∫—Ç—ã, –Ω–æ –∏—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è",
                "used_objects": [],
                "not_used_objects": not_used_objects
            }
            if debug_mode:
                response["debug"] = debug_info
                response["in_stoplist_filter_applied"] = True
                response["in_stoplist_level"] = in_stoplist
            return jsonify(response)

        # 2. –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
        try:
            # –°–æ–∑–¥–∞–µ–º –∫–∞—Ä—Ç—É —Å –∏–º–µ–Ω–µ–º –∏–∑ redis_key (–∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–º—è)
            map_name = redis_key.replace("cache:", "map_").replace(":", "_")
            map_result = geo.draw_custom_geometries(valid_objects, map_name)
            t3 = time.perf_counter()
            map_result["count"] = len(valid_objects)
            map_result["answer"] = answer
            map_result["names"] = [obj.get("name", "–ë–µ–∑ –∏–º–µ–Ω–∏") for obj in valid_objects]
            
            # –î–û–ë–ê–í–õ–Ø–ï–ú used_objects –∏ not_used_objects –ö –°–£–©–ï–°–¢–í–£–Æ–©–ï–ô –°–¢–†–£–ö–¢–£–†–ï
            map_result["used_objects"] = used_objects
            map_result["not_used_objects"] = not_used_objects
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ stoplist
            map_result["in_stoplist_filter_applied"] = True
            map_result["in_stoplist_level"] = in_stoplist
            map_result["stoplisted_count"] = len(stoplisted_objects)
            
            # –î–æ–±–∞–≤–ª—è–µ–º debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            debug_info["render_time"] = round(t3 - t2, 3)
            debug_info["total_time"] = round(time.perf_counter() - t0, 3)
            debug_info["map_generation"] = {
                "static_map": map_result.get("static_map"),
                "interactive_map": map_result.get("interactive_map"),
                "map_name": map_name
            }
            
            if debug_mode:
                map_result["debug"] = debug_info

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–µ—à (30 –º–∏–Ω—É—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º)
            set_cached_result(redis_key, map_result, expire_time=1800)
                
            return jsonify(map_result)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ –∫–∞—Ä—Ç—ã: {e}")
            debug_info["render_error"] = str(e)
            response = {
                "status": "error", 
                "message": f"–û—à–∏–±–∫–∞ –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ –∫–∞—Ä—Ç—ã: {e}",
                "objects": [obj["name"] for obj in valid_objects],
                "answer": answer,
                "in_stoplist_filter_applied": True,
                "in_stoplist_level": in_stoplist,
                "used_objects": used_objects,
                "not_used_objects": not_used_objects
            }
            if debug_mode:
                response["debug"] = debug_info
            return jsonify(response), 500
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Ä—è–¥–æ–º: {e}")
        debug_info["search_error"] = str(e)
        response = {
            "status": "error", 
            "message": f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Ä—è–¥–æ–º: {e}",
            "used_objects": [],
            "not_used_objects": []
        }
        if debug_mode:
            response["debug"] = debug_info
        return jsonify(response), 500
    finally:
        logging.info(
            "coords_to_map timings parse=%.3f search=%.3f render=%.3f total=%.3f",
            t_after_parse - t0,
            t2 - t1,
            t3 - t2,
            time.perf_counter() - t0,
        )

@app.route("/find_species_with_description", methods=["POST"])
def find_species_with_description():
    data = request.get_json()
    name = data.get("name")
    limit = data.get("limit", 5)
    offset = data.get("offset", 0)
    
    logger.info(f"POST /find_species_with_description - name: {name}, limit: {limit}, offset: {offset}")
    
    if not name:
        return jsonify({
            "status": "error",
            "message": "–ü–∞—Ä–∞–º–µ—Ç—Ä 'name' –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω",
            "used_objects": [],
            "not_used_objects": []
        }), 400
    
    result = slot_val.find_species_with_description(name, limit, offset)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–±—ä–µ–∫—Ç–∞—Ö
    used_objects = []
    not_used_objects = []
    
    if result.get("status") == "success" and result.get("results"):
        # –í—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –≤–∏–¥—ã —Å—á–∏—Ç–∞—é—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–º–∏
        for species in result["results"]:
            used_objects.append({
                "name": species.get("name", name),
                "type": "biological_entity"
            })
    else:
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –æ–±—ä–µ–∫—Ç –ø–æ–ø–∞–¥–∞–µ—Ç –≤ not_used_objects
        not_used_objects.append({
            "name": name,
            "type": "biological_entity" 
        })
    
    # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –æ–±—ä–µ–∫—Ç–∞–º–∏
    result["used_objects"] = used_objects
    result["not_used_objects"] = not_used_objects
    
    return jsonify(result)

@app.route("/")
def home():
    return "SalutBot API works!"

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5555)