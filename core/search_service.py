import os

import logging

from pathlib import Path

from typing import Dict, List, Any, Optional,Tuple,Union

from langchain_core.prompts import ChatPromptTemplate

from langchain_core.messages import HumanMessage,SystemMessage

from langchain_core.output_parsers import JsonOutputParser

from langchain_core.documents import Document

from core import query_parser, response_formatter

from infrastructure.vector_stores import init_vector_stores

from core.relational_service import RelationalService

import json

from .sql_agent import SQLAgent

from infrastructure.llm_integration import get_gigachat

from .geo_service import GeoService

import time

from langchain_community.embeddings import HuggingFaceEmbeddings

logging.basicConfig(

    level=logging.DEBUG,

    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'

)



logger = logging.getLogger(__name__)



class SearchService:

    def __init__(

    self, 

    faiss_index_path: str,

    embedding_model_path: str,

    llm_service: Optional[Any] = None,

    species_synonyms_path: Optional[str] = None

):

        """

        Args:

            faiss_index_path: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å FAISS –∏–Ω–¥–µ–∫—Å–∞–º–∏

            embedding_model_path: –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤

            llm_service: –°–µ—Ä–≤–∏—Å LLM (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)

        """

        self.faiss_index_path = faiss_index_path

        self.embedding_model_path = embedding_model_path

        self.query_modifier = query_parser.QueryModifier()

        self.llm_service = llm_service or get_gigachat()

        self.relational_service = RelationalService(species_synonyms_path)

        self.sql_agent = SQLAgent() 

        self.sql_tools = self.sql_agent.get_tools()

        self.geo_service = GeoService()

        self.vectorstores = init_vector_stores(

            faiss_index_path=faiss_index_path,

            embedding_model_path=embedding_model_path

        )

        self.species_synonyms = self._load_species_synonyms(species_synonyms_path)

        self._build_reverse_synonyms_index()



        self.embedding_model = HuggingFaceEmbeddings(

            model_name=embedding_model_path,

            model_kwargs={'device': 'cpu'},

            encode_kwargs={'normalize_embeddings': False}

        )

    def _init_gigachat(self):

        if self.llm is None:

            self.llm = get_gigachat()

            

    def _get_llm(self):

        if self.llm_service is None:

            self.llm_service = get_gigachat()

        return self.llm_service

    

    def _load_species_synonyms(self, file_path: Optional[str] = None):

        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–∏–Ω–æ–Ω–∏–º—ã –≤–∏–¥–æ–≤ –∏–∑ JSON —Ñ–∞–π–ª–∞"""

        if file_path is None:

            base_dir = Path(__file__).parent.parent

            file_path = base_dir / "json_files" / "species_synonyms.json"

        

        try:

            with open(file_path, 'r', encoding='utf-8') as f:

                return json.load(f)

        except FileNotFoundError:

            logger.error(f"–§–∞–π–ª —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")

            return {}

        except json.JSONDecodeError as e:

            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON —Ñ–∞–π–ª–∞ —Å–∏–Ω–æ–Ω–∏–º–æ–≤: {e}")

            return {}

        except Exception as e:

            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–∏–Ω–æ–Ω–∏–º–æ–≤: {e}")

            return {}

        

    def _build_reverse_synonyms_index(self):

        """–°–æ–∑–¥–∞–µ—Ç –æ–±—Ä–∞—Ç–Ω—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ —Å–∏–Ω–æ–Ω–∏–º–∞–º"""

        self.reverse_synonyms = {}

        for main_name, synonyms in self.species_synonyms.items():

            for synonym in synonyms:

                normalized_synonym = synonym.lower()

                if normalized_synonym not in self.reverse_synonyms:

                    self.reverse_synonyms[normalized_synonym] = []

                self.reverse_synonyms[normalized_synonym].append(main_name)

                

    def get_synonyms_for_name(self, name: str) -> Dict[str, Any]:

        """

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ —Å–∏–Ω–æ–Ω–∏–º—ã –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è

        Args:

            name: –ù–∞–∑–≤–∞–Ω–∏–µ –≤–∏–¥–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å –ª—é–±—ã–º —Å–∏–Ω–æ–Ω–∏–º–æ–º)

        Returns:

            –°–ª–æ–≤–∞—Ä—å —Å –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–æ—Ä–º–æ–π –∏ –≤—Å–µ–º–∏ —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏

        """

        if not name:

            return {"error": "–ù–∞–∑–≤–∞–Ω–∏–µ –Ω–µ —É–∫–∞–∑–∞–Ω–æ"}

        

        normalized_name = name.lower()

        

        main_forms = self.reverse_synonyms.get(normalized_name, [])

        

        if not main_forms:

            for main_name, synonyms in self.species_synonyms.items():

                if main_name.lower() == normalized_name:

                    main_forms = [main_name]

                    break

        

        if not main_forms:

            return {"error": f"–ù–∞–∑–≤–∞–Ω–∏–µ '{name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –±–∞–∑–µ —Å–∏–Ω–æ–Ω–∏–º–æ–≤"}

        

        result = {}

        for main_form in main_forms:

            result[main_form] = self.species_synonyms.get(main_form, [])

        

        return result

    

    def get_object_descriptions(self, object_name: str, object_type: str = "all") -> List[str]:

        """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –æ–±—ä–µ–∫—Ç–∞ –ª—é–±–æ–≥–æ —Ç–∏–ø–∞"""

        try:

            all_descriptions = []

            

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø—ã –æ–±—ä–µ–∫—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞

            search_types = []

            if object_type == "all":

                search_types = ["biological_entity", "geographical_entity", "modern_human_made","organization","research_project","volunteer_initiative","ancient_human_made"]

            else:

                search_types = [object_type]

            

            for entity_type in search_types:

                # –î–ª—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –æ–±—ä–µ–∫—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å

                descriptions = self.relational_service.get_object_descriptions(object_name, entity_type)

                if descriptions:

                    all_descriptions.extend(descriptions)

                        

            return list(set(all_descriptions))

                

        except Exception as e:

            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ–ø–∏—Å–∞–Ω–∏—è –æ–±—ä–µ–∫—Ç–∞ '{object_name}': {str(e)}")

            return []

        

    def get_object_descriptions_by_filters(

        self,

        filter_data: Dict[str, Any],

        object_type: str = "all",

        limit: int = 10

    ) -> List[Dict]:

        """

        –ü–æ–∏—Å–∫ –æ–ø–∏—Å–∞–Ω–∏–π –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ —Ñ–∏–ª—å—Ç—Ä–∞–º –∏–∑ JSON body

        

        Args:

            filter_data: –°–ª–æ–≤–∞—Ä—å —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏

            object_type: –¢–∏–ø –æ–±—ä–µ–∫—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞

            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

            

        Returns:

            –°–ø–∏—Å–æ–∫ –æ–ø–∏—Å–∞–Ω–∏–π –æ–±—ä–µ–∫—Ç–æ–≤

        """

        try:

            return self.relational_service.get_object_descriptions_by_filters(

                filter_data=filter_data,

                object_type=object_type,

                limit=limit

            )

                

        except Exception as e:

            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ —Ñ–∏–ª—å—Ç—Ä–∞–º: {str(e)}")

            return []

    def _generate_gigachat_answer(self, question: str, context: str) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç GigaChat –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–æ–ø—Ä–æ—Å–∞ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –æ—Ç–≤–µ—Ç–æ–º –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        llm = self._get_llm()
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", (
                "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ë–∞–π–∫–∞–ª—å—Å–∫–æ–π –ø—Ä–∏—Ä–æ–¥–Ω–æ–π —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∏. "
                "–ò—Å–ø–æ–ª—å–∑—É–π —Ç–≤–æ—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –¥–ª—è —Ç–æ—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.\n\n"
                "–û—Å–æ–±—ã–µ —É–∫–∞–∑–∞–Ω–∏—è:\n"
                "- –ù–∞ –≤–æ–ø—Ä–æ—Å—ã '—Å–∫–æ–ª—å–∫–æ' - –ø–æ–¥—Å—á–∏—Ç–∞–π –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π\n"
                "–ù–∞–ø—Ä–∏–º–µ—Ä, –Ω–∞ –≤–æ–ø—Ä–æ—Å '–°–∫–æ–ª—å–∫–æ –º—É–∑–µ–µ–≤?' –ø—Ä–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ '–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: 98 (–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–∫–ª—é—á–µ–Ω–æ —Ç–æ–ø-5 –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏)', –Ω—É–∂–Ω–æ –æ—Ç–≤–µ—Ç–∏—Ç—å –æ–∫–æ–ª–æ 98 –º—É–∑–µ–µ–≤ –∏ –∑–∞—Ç–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –º—É–∑–µ—è –∏–∑ —Ç–æ–ø –∑–∞–ø–∏—Å–µ–π"
                "- –ë—É–¥—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º –∏ –ª–∞–∫–æ–Ω–∏—á–Ω—ã–º\n"
                "- –î–∞–∂–µ –ø—Ä–∏ –Ω–µ–ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–µ—Ç–∞–ª–∏\n\n"
                f"–¢–≤–æ—è –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π:\n{context}\n\n"
                f"–í–æ–ø—Ä–æ—Å: {question}\n\n"
                "–û—Ç–≤–µ—Ç:"
            ))
        ])
        
        try:
            chain = prompt | llm
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
            response = chain.invoke({"question": question, "context": context})
            
            # –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –õ–æ–≥–∏—Ä—É–µ–º –≤—Å—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ—Ç–≤–µ—Ç–∞
            logger.debug(f"–ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç GigaChat: {response}")
            logger.debug(f"–¢–∏–ø –æ—Ç–≤–µ—Ç–∞: {type(response)}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –º–µ—Å—Ç–∞ –¥–ª—è finish_reason
            finish_reason = None
            
            # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º response_metadata
            if hasattr(response, 'response_metadata'):
                logger.debug(f"response_metadata: {response.response_metadata}")
                finish_reason = response.response_metadata.get('finish_reason')
            
            # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—Ä—É–≥–∏–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
            if not finish_reason and hasattr(response, 'llm_output'):
                logger.debug(f"llm_output: {response.llm_output}")
                if isinstance(response.llm_output, dict):
                    finish_reason = response.llm_output.get('finish_reason')
            
            # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ç—Ä–∏–±—É—Ç—ã —Å–∞–º–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞
            if not finish_reason and hasattr(response, 'finish_reason'):
                finish_reason = response.finish_reason
                
            # 4. –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            if not finish_reason and hasattr(response, 'additional_kwargs'):
                logger.debug(f"additional_kwargs: {response.additional_kwargs}")
                finish_reason = response.additional_kwargs.get('finish_reason')
            
            logger.debug(f"–ù–∞–π–¥–µ–Ω finish_reason: {finish_reason}")
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ª–æ–≤–∞—Ä—å —Å –æ—Ç–≤–µ—Ç–æ–º –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
            return {
                "content": response.content.strip() if hasattr(response, 'content') else "",
                "finish_reason": finish_reason,
                "success": finish_reason != 'blacklist'
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ GigaChat: {str(e)}")
            
            # –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–µ
            logger.debug(f"–¢–∏–ø –∏—Å–∫–ª—é—á–µ–Ω–∏—è: {type(e)}")
            if hasattr(e, 'response'):
                logger.debug(f"Response –≤ –∏—Å–∫–ª—é—á–µ–Ω–∏–∏: {e.response}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –æ—à–∏–±–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ blacklist
            error_str = str(e).lower()
            if any(phrase in error_str for phrase in ['blacklist', 'restricted', 'content policy', 'finish_reason']):
                return {
                    "content": "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è –Ω–µ –º–æ–≥—É —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.",
                    "finish_reason": "blacklist",
                    "success": False
                }
            
            return {
                "content": "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.",
                "finish_reason": "error",
                "success": False
            }

    

    def search_objects_by_embedding(

    self, 

    query_embedding: List[float],

    object_type: str = "all",

    limit: int = 10,

    similarity_threshold: float = 0.05

) -> List[Dict]:

        """

        –ü–æ–∏—Å–∫ –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–º—É —Å—Ö–æ–¥—Å—Ç–≤—É —Å –∑–∞–ø—Ä–æ—Å–æ–º

        

        Args:

            query_embedding: –≠–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞

            object_type: –¢–∏–ø –æ–±—ä–µ–∫—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞

            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

            similarity_threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏

            

        Returns:

            –°–ø–∏—Å–æ–∫ –æ–ø–∏—Å–∞–Ω–∏–π –æ–±—ä–µ–∫—Ç–æ–≤ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å—Ö–æ–∂–µ—Å—Ç–∏

        """

        try:

            all_descriptions = []

            

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø—ã –æ–±—ä–µ–∫—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞

            search_types = []

            if object_type == "all":

                search_types = ["biological_entity", "geographical_entity", "modern_human_made", 

                            "organization", "research_project", "volunteer_initiative", "ancient_human_made"]

            else:

                search_types = [object_type]

            

            for entity_type in search_types:

                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥ —Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ —ç–º–±–µ–¥–¥–∏–Ω–≥—É

                # –î–ª—è —ç—Ç–æ–≥–æ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å –ø—É—Å—Ç–æ–π object_name –∏ –ø–æ–ª–∞–≥–∞—Ç—å—Å—è –Ω–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥

                descriptions = self.relational_service.search_objects_by_embedding_only(

                    query_embedding=query_embedding,

                    object_type=entity_type,

                    limit=limit,

                    similarity_threshold=similarity_threshold

                )

                if descriptions:

                    all_descriptions.extend(descriptions)

            

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å—Ö–æ–∂–µ—Å—Ç–∏ –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ

            all_descriptions.sort(key=lambda x: x.get("similarity", 0), reverse=True)

            return all_descriptions[:limit]

                

        except Exception as e:

            logger.error(f"–û—à–∏–±–∫–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –æ–±—ä–µ–∫—Ç–æ–≤: {str(e)}")

            return []

        

    def get_object_descriptions_with_embedding(self, object_name: str, object_type: str, 

                                        query_embedding: List[float], 

                                        limit: int = 10, 

                                        similarity_threshold: float = 0.05) -> List[Dict]:

        """–ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ —Å —É—á–µ—Ç–æ–º —Å—Ö–æ–∂–µ—Å—Ç–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""

        try:

            all_descriptions = []

            

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø—ã –æ–±—ä–µ–∫—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞

            search_types = []

            if object_type == "all":

                search_types = ["biological_entity", "geographical_entity", "modern_human_made","organization","research_project","volunteer_initiative","ancient_human_made"]

            else:

                search_types = [object_type]

            

            for entity_type in search_types:

                # –î–ª—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –æ–±—ä–µ–∫—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å

                descriptions = self.relational_service.get_object_descriptions_with_embedding(

                    object_name, entity_type, query_embedding, limit, similarity_threshold

                )

                if descriptions:

                    all_descriptions.extend(descriptions)

            

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å—Ö–æ–∂–µ—Å—Ç–∏ –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ

            all_descriptions.sort(key=lambda x: x.get("similarity", 0), reverse=True)

            return all_descriptions[:limit]

                

        except Exception as e:

            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ–ø–∏—Å–∞–Ω–∏–π —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–º –¥–ª—è '{object_name}': {str(e)}")

            return []

    

    def search_images_by_features(

    self,

    species_name: str,

    features: Dict[str, Any]

) -> Dict[str, Any]:

        """

        –ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –≤–∏–¥–∞ –∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º

        

        Args:

            species_name: –ù–∞–∑–≤–∞–Ω–∏–µ –±–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –≤–∏–¥–∞

            features: –°–ª–æ–≤–∞—Ä—å —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏

            

        Returns:

            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π

        """

        try:

            synonyms_data = self.get_synonyms_for_name(species_name)

            

            return self.relational_service.search_images_by_features(

                species_name=species_name,

                features=features,

                synonyms_data=synonyms_data

            )

        except Exception as e:

            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º: {str(e)}")

            return {

                "status": "error",

                "message": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {str(e)}"

            }

            

    def get_text_descriptions(self, species_name: str) -> List[str]:

        """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –≤–∏–¥–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–∏–Ω–æ–Ω–∏–º–æ–≤"""

        try:

            synonyms_data = self.get_synonyms_for_name(species_name)

            all_descriptions = []

            

            if "error" not in synonyms_data:

                for main_form, synonyms in synonyms_data.items():

                    all_names = [main_form] + synonyms

                    for name in all_names:

                        descriptions = self.relational_service.get_text_descriptions(name)

                        if descriptions:

                            all_descriptions.extend(descriptions)

            else:

                descriptions = self.relational_service.get_text_descriptions(species_name)

                if descriptions:

                    all_descriptions.extend(descriptions)

                    

            return list(set(all_descriptions))

                    

        except Exception as e:

            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ–ø–∏—Å–∞–Ω–∏—è —á–µ—Ä–µ–∑ RelationalService: {str(e)}")

            return []

        

    def filter_text_descriptions_with_gigachat(self, user_query: str, descriptions: List[Dict]) -> List[Dict]:

        """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π –≤–∏–¥–æ–≤ —á–µ—Ä–µ–∑ GigaChat"""

        llm = self._get_llm()

        

        if not descriptions:

            return []



        descriptions_text = "\n\n".join(

            f"–û–ø–∏—Å–∞–Ω–∏–µ {i+1}:\n{desc.get('content', '')[:800]}..."

            for i, desc in enumerate(descriptions)

        )

        

        prompt = ChatPromptTemplate.from_messages([

            SystemMessage(content=(

                "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –±–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–º –≤–∏–¥–∞–º –ë–∞–π–∫–∞–ª—å—Å–∫–æ–≥–æ —Ä–µ–≥–∏–æ–Ω–∞. –§–∏–ª—å—Ç—Ä—É–π —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è –°–¢–†–û–ì–û –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å—É.\n\n"

                

                "## –ö–†–ò–¢–ï–†–ò–ò –§–ò–õ–¨–¢–†–ê–¶–ò–ò:\n"

                "1. –û–ø–∏—Å–∞–Ω–∏–µ –î–û–õ–ñ–ù–û –ø–æ–ª–Ω–æ –∏ —Ç–æ—á–Ω–æ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n"

                "2. –ö–æ—Å–≤–µ–Ω–Ω–æ–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Ç–µ–º—ã = –ù–ï–†–ï–õ–ï–í–ê–ù–¢–ù–û\n"

                "3. –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –æ—Ç–¥–∞–µ—Ç—Å—è –æ–ø–∏—Å–∞–Ω–∏—è–º, –∫–æ—Ç–æ—Ä—ã–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –ø–æ—Å–≤—è—â–µ–Ω—ã –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º–æ–π —Ç–µ–º–µ\n\n"

                

                "## –ü–†–ò–ú–ï–†–´:\n"

                "–ó–∞–ø—Ä–æ—Å: '—à–∏—à–∫–∞ –ø–∏—Ö—Ç—ã'\n"

                "‚úì –†–ï–õ–ï–í–ê–ù–¢–ù–û: –æ–ø–∏—Å–∞–Ω–∏–µ, —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –ø–æ—Å–≤—è—â–µ–Ω–Ω–æ–µ —à–∏—à–∫–∞–º, –∏—Ö —Å—Ç—Ä–æ–µ–Ω–∏—é, –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—è–º\n"

                "‚úó –ù–ï–†–ï–õ–ï–í–ê–ù–¢–ù–û: –æ–ø–∏—Å–∞–Ω–∏–µ, –≥–¥–µ —à–∏—à–∫–∞ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –≤—Å–∫–æ–ª—å–∑—å —Å—Ä–µ–¥–∏ –¥—Ä—É–≥–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏\n\n"

                

                "–ó–∞–ø—Ä–æ—Å: '–∫–æ—Ä–∞ –ø–∏—Ö—Ç—ã –∏ –ø–∏—Ç–∞–Ω–∏–µ –∂–∏–≤–æ—Ç–Ω—ã—Ö'\n"

                "‚úì –†–ï–õ–ï–í–ê–ù–¢–ù–û: –æ–ø–∏—Å–∞–Ω–∏–µ –æ —Ç–æ–º, –∫–∞–∫–∏–µ –∂–∏–≤–æ—Ç–Ω—ã–µ –ø–∏—Ç–∞—é—Ç—Å—è –∫–æ—Ä–æ–π –ø–∏—Ö—Ç—ã\n"

                "‚úó –ù–ï–†–ï–õ–ï–í–ê–ù–¢–ù–û: –æ–±—â–µ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø–∏—Ö—Ç—ã —Å –∫—Ä–∞—Ç–∫–∏–º —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º –∫–æ—Ä—ã\n\n"

                

                "## –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê –¢–û–õ–¨–ö–û JSON:\n"

                "{\n"

                "  \"relevant_descriptions\": [—Å–ø–∏—Å–æ–∫ —Ü–µ–ª–æ—á–∏—Å–ª–µ–Ω–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π],\n"

                "  \"no_relevant_descriptions\": bool (true –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ)\n"

                "}\n\n"

                

                "## –í–ê–ñ–ù–û:\n"

                "- –ë—É–¥—å —Å—Ç—Ä–æ–≥–∏–º –≤ –æ—Ü–µ–Ω–∫–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏\n"

                "- –ù–µ –≤–∫–ª—é—á–∞–π –æ–ø–∏—Å–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –ª–∏—à—å –∫–æ—Å–≤–µ–Ω–Ω–æ –∫–∞—Å–∞—é—Ç—Å—è —Ç–µ–º—ã\n"

                "- –ï—Å–ª–∏ –Ω–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–π, –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ç–≤–µ—á–∞—é—â–∏—Ö –Ω–∞ –∑–∞–ø—Ä–æ—Å, –≤–µ—Ä–Ω–∏ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫\n"

                "- –í–æ–∑–≤—Ä–∞—â–∞–π –¢–û–õ–¨–ö–û —Ü–µ–ª—ã–µ —á–∏—Å–ª–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: [0, 2]), –ù–ï –≤–æ–∑–≤—Ä–∞—â–∞–π —Å—Ä–µ–∑—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä: [0:2])"

            )),

            HumanMessage(content=(

                f"–ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {user_query}\n\n"

                f"–î–û–°–¢–£–ü–ù–´–ï –û–ü–ò–°–ê–ù–ò–Ø:\n{descriptions_text}\n\n"

                "–ü–†–û–ê–ù–ê–õ–ò–ó–ò–†–£–ô –∏ –í–ï–†–ù–ò JSON –û–¢–í–ï–¢ –ë–ï–ó –ö–û–ú–ú–ï–ù–¢–ê–†–ò–ï–í:"

            ))

        ])



        try:

            chain = prompt | llm | JsonOutputParser()

            response = chain.invoke({"user_query": user_query, "descriptions": descriptions_text})

            logger.debug(response)

            if response.get("no_relevant_descriptions", False):

                return []

                

            # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–Ω–¥–µ–∫—Å–æ–≤

            relevant_indices = []

            raw_indices = response.get("relevant_descriptions", [])

            

            logger.debug(f"Raw indices from LLM: {raw_indices}, type: {type(raw_indices)}")

            

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –æ—Ç–≤–µ—Ç–∞

            if isinstance(raw_indices, (int, str)):

                raw_indices = [raw_indices]

                

            for idx in raw_indices:

                try:

                    # –ï—Å–ª–∏ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞, –ø—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —á–∏—Å–ª–æ

                    if isinstance(idx, str):

                        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π —Å—Ä–µ–∑–æ–≤

                        if ':' in idx:

                            try:

                                parts = idx.split(':')

                                start = int(parts[0]) if parts[0] else 0

                                stop = int(parts[1]) if parts[1] else len(descriptions)

                                step = int(parts[2]) if len(parts) > 2 and parts[2] else 1

                                slice_indices = list(range(start, stop, step))

                                for slice_idx in slice_indices:

                                    if 0 <= slice_idx < len(descriptions):

                                        relevant_indices.append(slice_idx)

                            except ValueError:

                                continue

                        else:

                            # –û–±—ã—á–Ω–æ–µ —á–∏—Å–ª–æ –≤ —Å—Ç—Ä–æ–∫–µ

                            try:

                                num_idx = int(idx)

                                if 0 <= num_idx < len(descriptions):

                                    relevant_indices.append(num_idx)

                            except ValueError:

                                continue

                    # –ï—Å–ª–∏ —ç—Ç–æ —á–∏—Å–ª–æ

                    elif isinstance(idx, int):

                        if 0 <= idx < len(descriptions):

                            relevant_indices.append(idx)

                except (ValueError, TypeError) as e:

                    logger.warning(f"Invalid index '{idx}': {e}")

                    continue



            # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º

            relevant_indices = sorted(set(relevant_indices))

            if not relevant_indices:

                logger.debug("No relevant indices found after processing")

                return []

            logger.debug(f"Processed indices: {relevant_indices}")

            

            return [descriptions[i] for i in relevant_indices]

            

        except Exception as e:

            logger.error(f"–û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ–ø–∏—Å–∞–Ω–∏–π —á–µ—Ä–µ–∑ GigaChat: {str(e)}")

            return descriptions

            

    def _filter_docs_with_gigachat(self, query: str, docs: List[Document]) -> List[int]:

        """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ LLM"""

        llm = self._get_llm()

        

        if not docs or not query:

            return list(range(len(docs))) if docs else []



        docs_text = "\n\n".join(

            f"–î–æ–∫—É–º–µ–Ω—Ç {i}:\n{doc.page_content[:1000]}"

            for i, doc in enumerate(docs))

        

        prompt = ChatPromptTemplate.from_messages([

        SystemMessage(content=(

            "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ë–∞–π–∫–∞–ª—å—Å–∫–æ–π —ç–∫–æ—Å–∏—Å—Ç–µ–º–µ. –§–∏–ª—å—Ç—Ä—É–π –¥–æ–∫—É–º–µ–Ω—Ç—ã –°–¢–†–û–ì–û –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º:\n"

            "1. –î–æ–∫—É–º–µ–Ω—Ç –î–û–õ–ñ–ï–ù —Å–æ–¥–µ—Ä–∂–∞—Ç—å –í–°–ï —ç–ª–µ–º–µ–Ω—Ç—ã –∑–∞–ø—Ä–æ—Å–∞: [–≤–∏–¥ —Ä–∞—Å—Ç–µ–Ω–∏—è] + [—Ç–∏–ø –º–µ—Å—Ç–Ω–æ—Å—Ç–∏] + [–ø–æ–≥–æ–¥–∞]\n"

            "2. –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ = –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ\n"

            "3. –ï—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –õ–Æ–ë–û–ô —ç–ª–µ–º–µ–Ω—Ç ‚Üí –¥–æ–∫—É–º–µ–Ω—Ç –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω\n\n"

            

            "## –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –¢–û–õ–¨–ö–û JSON:\n"

            "{\n"

            "  \"relevant_docs\": [—Å–ø–∏—Å–æ–∫ int-–∏–Ω–¥–µ–∫—Å–æ–≤] | [],\n"

            "  \"no_relevant_docs\": bool\n"

            "}\n\n"

            

            "## –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã:\n"

            "–ó–∞–ø—Ä–æ—Å: '–ü–æ–∫–∞–∂–∏ –û—Å—Ç—Ä–æ–ª–æ–¥–æ—á–Ω–∏–∫ –≤ —è—Å–Ω—É—é –ø–æ–≥–æ–¥—É –Ω–∞ –ø–æ–±–µ—Ä–µ–∂—å–µ'\n"

            "‚Üí –î–æ–ø—É—Å—Ç–∏–º—ã–π –æ—Ç–≤–µ—Ç: {\"relevant_docs\": [], \"no_relevant_docs\": true} (–µ—Å–ª–∏ –Ω–µ—Ç –ø–æ–ª–Ω–æ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è)\n\n"

            

            "–ó–∞–ø—Ä–æ—Å: '–ß–µ—Ä–µ–ø–æ–ø–ª–æ–¥–Ω–∏–∫ —â–µ—Ç–∏–Ω–∏—Å—Ç–æ–≤–∞—Ç—ã–π –Ω–∞ –ø–µ—Å—á–∞–Ω–æ–º –ø–ª—è–∂–µ'\n"

            "‚Üí –ù–µ–¥–æ–ø—É—Å—Ç–∏–º–æ: —É–∫–∞–∑–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø—Ä–æ —á–∞–µ–∫\n\n"

            

            "## –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:\n"

            "- –ù–µ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–π –∑–∞–ø—Ä–æ—Å —Ä–∞—Å—à–∏—Ä–∏—Ç–µ–ª—å–Ω–æ\n"

            "- –†–∞—Å—Ç–µ–Ω–∏—è: —Ç–æ—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π\n"

            "- –ü–æ–≥–æ–¥–∞: —Ç–æ–ª—å–∫–æ —è–≤–Ω—ã–µ —É–∫–∞–∑–∞–Ω–∏—è –≤ —Ç–µ–∫—Å—Ç–µ\n"

            "- –õ–Æ–ë–û–ï –Ω–∞—Ä—É—à–µ–Ω–∏–µ ‚Üí no_relevant_docs: true"

        )),

        HumanMessage(content=(

            f"–ó–ê–ü–†–û–°: {query}\n\n"

            f"–î–û–ö–£–ú–ï–ù–¢–´ –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:\n{docs_text}\n\n"

            "–í–ï–†–ù–ò JSON –û–¢–í–ï–¢ –ë–ï–ó –ö–û–ú–ú–ï–ù–¢–ê–†–ò–ï–í:"

        ))

    ])



        try:

            chain = prompt | llm | JsonOutputParser()

            response = chain.invoke({"query": query, "docs": docs_text})

            

            # –í–∞–ª–∏–¥–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞

            if response.get("no_relevant_docs", False):

                return []

                

            relevant_indices = [

                idx for idx in response.get("relevant_docs", [])

                if isinstance(idx, int) and 0 <= idx < len(docs)

            ]

            return relevant_indices

            

        except Exception as e:

            logger.error(f"–û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ GigaChat: {str(e)}")

            return list(range(len(docs)))





    def ask_question(

    self,

    question: str,

    similarity_threshold: float = 0.52,

    similarity_deviation: float = None,

    use_gigachat: bool = False,

    user_id: Optional[str] = None,

    debug_mode: bool = False,

    knowledge_base_type: str = "vector",

    query_formatter: Optional[str] = None,

    strict_filter: bool = False,

    filter_words: Optional[List[str]] = None  # –ù–æ–≤—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä

) -> Dict[str, Any]:

        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–æ–ø—Ä–æ—Å–æ–≤"""

        try:

            logger.debug(f"–ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–æ–ø—Ä–æ—Å–∞: '{question}' (knowledge_base={knowledge_base_type}, agent={query_formatter == 'agent'}, strict_filter={strict_filter})")

            if knowledge_base_type == "relational":

                if query_formatter == "agent":

                    return self._ask_agent(

                        question=question,

                        debug_mode=debug_mode

                    )

                else:

                    return self._ask_relational(

                        question=question,

                        query_formatter=query_formatter,

                        debug_mode=debug_mode,

                    )

            else:

                return self._ask_vector(

            question=question,

            similarity_threshold=similarity_threshold,

            similarity_deviation=similarity_deviation,

            use_gigachat=use_gigachat,

            debug_mode=debug_mode,

            user_id=user_id,

            strict_filter=strict_filter,

            filter_words=filter_words  

        )

        except Exception as e:

            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ ask_question: {str(e)}")

            return self._build_error_response(str(e), debug_mode)

        

    def _ask_vector(

        self,

        question: str,

        similarity_threshold: float,

        similarity_deviation: Optional[float],

        use_gigachat: bool,

        debug_mode: bool,

        user_id: Optional[str] = None,

        strict_filter: bool = False,

        filter_words: Optional[List[str]] = None  

    ) -> Dict[str, Any]:

        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π

        

        Args:

            question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

            similarity_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏

            similarity_deviation: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç –ª—É—á—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

            use_gigachat: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GigaChat –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏

            debug_mode: –í–∫–ª—é—á–∏—Ç—å –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é

            

        Returns:

            –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ–∏—Å–∫–∞

        """

        modified_query = self.query_modifier.modify(question)

        requested_types = self._extract_requested_types(modified_query)

        

        search_stores = self._get_search_stores(requested_types)

        if not search_stores:

            return self._build_empty_response(

                "–ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞",

                debug_mode

            )

        

        all_results, all_scores = self._search_documents(

            question,

            search_stores,

            similarity_threshold,

            debug_mode

        )

        

        if not all_results:

            return self._build_empty_response(

                "–ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ",

                debug_mode

            )

        

        if similarity_deviation is not None:

            filtered_results, filtered_scores = self._apply_dynamic_threshold(

                all_results,

                all_scores,

                similarity_deviation,

                debug_mode

            )

        else:

            filtered_results = all_results

            filtered_scores = all_scores

        

        if use_gigachat:

            try:

                logger.debug(f"–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è GigaChat. –î–æ: {len(filtered_results)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

                filtered_indices = self._filter_docs_with_gigachat(question, filtered_results)

                logger.debug(f"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {len(filtered_indices)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

                if not filtered_indices:

                    logger.info("GigaChat –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–ª –í–°–ï –¥–æ–∫—É–º–µ–Ω—Ç—ã –∫–∞–∫ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ")

                    return self._build_empty_response(

                        "–ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ",

                        debug_mode

                    )

                    

                final_results = [filtered_results[i] for i in filtered_indices]

                final_scores = [filtered_scores[i] for i in filtered_indices] if debug_mode else None

                logger.debug(f"Gigachat —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: {final_results}")

                logger.debug(f"Gigachat –æ—Ü–µ–Ω–∫–∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î: {final_scores}")

            except Exception as e:

                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ GigaChat: {str(e)}")

                final_results = filtered_results

                final_scores = filtered_scores if debug_mode else None

        else:

            final_results = filtered_results

            final_scores = filtered_scores if debug_mode else None

        if strict_filter and filter_words:

            logger.debug(f"Applying strict filter with words: {filter_words}")

            temp_results = []

            

            for doc in final_results:

                content = doc.page_content.lower()

                all_words_found = True

                

                for word in filter_words:

                    word_lower = word.lower()

                    synonyms = self.species_synonyms.get(word_lower, [word_lower])

                    word_found = any(synonym.lower() in content for synonym in synonyms)

                    

                    if not word_found:

                        all_words_found = False

                        break

                        

                if all_words_found:

                    temp_results.append(doc)

                    

            final_results = temp_results

            if debug_mode and final_scores is not None:

                final_scores = [s for i, s in enumerate(final_scores) 

                            if i < len(final_results)]

        logger.debug(final_results)

        if not final_results:

            return self._build_empty_response(

                "–ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ",

                debug_mode

            )

        return self._format_response(

            final_results,

            requested_types,

            final_scores,

            debug_mode,

            user_id=user_id

        )

    

    def _ask_relational(

        self,

        question: str,

        query_formatter: str,

        debug_mode: bool

    ) -> Dict[str, Any]:

        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ —Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π

        

        Args:

            question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

            query_formatter: –°–ø–æ—Å–æ–± —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞ ("gigachat")

            debug_mode: –í–∫–ª—é—á–∏—Ç—å –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é

            

        Returns:

            –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ–∏—Å–∫–∞

        """

        try:

            if query_formatter == "gigachat":

                result = self.relational_service.process_question(question)

            else:

                raise ValueError(f"Unsupported formatter: {query_formatter}")

            

            if not result["success"]:

                return self._build_empty_response(

                    result.get("error", "–û—à–∏–±–∫–∞ —Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π –ë–î"),

                    debug_mode

                )

            

            return self._format_relational_response(

                results=result["results"],

                debug_mode=debug_mode

            )

            

        except Exception as e:

            logger.error(f"–û—à–∏–±–∫–∞ —Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π –ë–ó: {str(e)}")

            return self._build_error_response(str(e), debug_mode)

        

    def _get_agent_prompt(self) -> ChatPromptTemplate:

        """–ü—Ä–æ–º–ø—Ç –¥–ª—è –∞–≥–µ–Ω—Ç–∞"""

        return ChatPromptTemplate.from_messages([

            ("system", (

                "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ë–∞–π–∫–∞–ª—å—Å–∫–æ–π –ø—Ä–∏—Ä–æ–¥–Ω–æ–π —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∏. "

                "–ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö. "

                "–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –≤—ã–±–∏—Ä–∞–π –ø–æ–¥—Ö–æ–¥—è—â–∏–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç.\n\n"

                "–î–æ—Å—Ç—É–ø–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã:\n"

                "1. simple_search_tool: –î–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –≤–∏–¥–∞\n"

                "2. attribute_search_tool: –î–ª—è –ø–æ–∏—Å–∫–∞ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏\n"

                "3. geo_search_tool: –î–ª—è –≥–µ–æ–ø–æ–∏—Å–∫–∞\n"

                "4. text_description_tool: –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è\n\n"

                "–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:\n"

                "- '–ü–æ–∫–∞–∂–∏ –¥–∞—É—Ä—Å–∫–æ–≥–æ –µ–∂–∞' ‚Üí simple_search_tool\n"

                "- '–ü–æ–∫–∞–∂–∏ —à–∏—à–∫—É —Å–∏–±–∏—Ä—Å–∫–æ–π —Å–æ—Å–Ω—ã' ‚Üí attribute_search_tool\n"

                "- '–ì–¥–µ –º–æ–∂–Ω–æ –≤—Å—Ç—Ä–µ—Ç–∏—Ç—å –æ–ª—å—Ö–æ–Ω—Å–∫—É—é –ø–æ–ª–µ–≤–∫—É' ‚Üí geo_search_tool\n"

                "- '–†–∞—Å—Å–∫–∞–∂–∏ –æ –±–∞–π–∫–∞–ª—å—Å–∫–æ–π –Ω–µ—Ä–ø–µ' ‚Üí text_description_tool\n"

            )),

            ("human", "{input}")

        ])

    def _format_agent_response(self, raw_response: str, debug_mode: bool) -> Dict[str, Any]:

        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –∞–≥–µ–Ω—Ç–∞ —Å —É—á–µ—Ç–æ–º —Ç–∏–ø–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""

        response = {

            "answer": "",

            "multi_url": {

                "image_urls": [],

                "file_urls": [],

                "geo_places": []

            }

        }

        

        try:

            # –°–Ω–∞—á–∞–ª–∞ –ø–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç –∞–≥–µ–Ω—Ç–∞

            agent_response = json.loads(raw_response)

            

            # –ï—Å–ª–∏ –µ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ—à–∏–±–∫–µ

            if "error" in agent_response:

                response["answer"] = f"–û—à–∏–±–∫–∞: {agent_response['error']}"

                if debug_mode:

                    response["debug_info"] = agent_response.get("debug", {})

                return response

            

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –æ—Ç–≤–µ—Ç

            answer_data = agent_response.get("answer", "")

            

            try:

                # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ JSON (–µ—Å–ª–∏ —ç—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞)

                results = json.loads(answer_data)

            except:

                # –ï—Å–ª–∏ –Ω–µ JSON, –∑–Ω–∞—á–∏—Ç —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç

                results = answer_data

            

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

            if isinstance(results, list):

                for item in results:

                    if isinstance(item, dict) and "image_path" in item:

                        image_url = item["image_path"]

                        response["multi_url"]["image_urls"].append(image_url)

                        

                        desc = f"{item.get('name', '–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ')}"

                        if item.get('description'):

                            desc += f" - {item['description']}"

                        response["answer"] += f"üì∑ {desc}\n"

                    

                    elif isinstance(item, dict) and "text_content" in item:

                        response["answer"] += f"üìù {item['text_content']}\n"

                    

                    elif isinstance(item, dict) and "error" in item:

                        response["answer"] += f"‚ö†Ô∏è {item['error']}\n"

                        if "suggestions" in item:

                            response["answer"] += "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:\n- " + "\n- ".join(item["suggestions"]) + "\n"

            else:

                # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –Ω–µ —Å–ø–∏—Å–æ–∫, –ø—Ä–æ—Å—Ç–æ –≤—ã–≤–æ–¥–∏–º –µ–≥–æ

                response["answer"] = str(results)

            

            # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –ø—É—Å—Ç–æ–π, –Ω–æ –µ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

            if not response["answer"] and "parameters" in agent_response:

                params = agent_response["parameters"]

                response["answer"] = (

                    f"–ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: "

                    f"species_name='{params.get('species_name', '')}', "

                    f"search_type='{params.get('search_type', '')}'"

                )

            

        except json.JSONDecodeError:

            response["answer"] = raw_response

        

        if debug_mode:

            response["debug_info"] = agent_response.get("debug", {})

            

        return response

            

    def _ask_agent(self, question: str, debug_mode: bool) -> Dict[str, Any]:

        """–î–µ–ª–µ–≥–∏—Ä—É–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç—É"""

        try:

            logger.debug(f"Starting agent with question: {question}")

            response = self.sql_agent.ask(question)

            logger.debug(f"Agent response: {response}")

            return self._format_agent_response(response, debug_mode)

        except Exception as e:

            logger.error(f"–û—à–∏–±–∫–∞ SQL-–∞–≥–µ–Ω—Ç–∞: {str(e)}", exc_info=True)

            return self._build_error_response(str(e), debug_mode)

        

    def _format_relational_response(

    self,

    results: List[Dict],

    debug_mode: bool

) -> Dict[str, Any]:

        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –∏–∑ —Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö

        

        Args:

            results: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑ –ë–î

            debug_mode: –í–∫–ª—é—á–∏—Ç—å –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é

            

        Returns:

            –°–ª–æ–≤–∞—Ä—å —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º

        """

        answer_parts = []

        image_urls = []

        file_urls = []

        geo_places = []



        for item in results:

            if item.get("type") == "text":

                content = item.get("content", "")

                if content:

                    answer_parts.append(content)

            

            elif item.get("type") == "image":

                image_path = item.get("path") or item.get("image_path") or item.get("file_path")

                if image_path:

                    image_urls.append(image_path)

                    description = item.get("description") or item.get("image_caption") or "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"

                    answer_parts.append(f"üì∑ {description}")

            

            elif item.get("type") == "file":

                file_path = item.get("path") or item.get("file_path")

                if file_path:

                    file_urls.append(file_path)

                    description = item.get("description") or item.get("name") or "–§–∞–π–ª"

                    answer_parts.append(f"üìÑ {description}")

            

            if item.get("location_name"):

                geo_places.append(item["location_name"])

            elif item.get("geojson"):

                geo_places.append("–ì–µ–æ–æ–±—ä–µ–∫—Ç")



        answer = "\n\n".join(answer_parts) if answer_parts else "–î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"

        logger.debug(f"{image_urls} - –∫–∞—Ä—Ç–∏–Ω–∫–∏")

        response = {

            "answer": answer,

            "multi_url": {

                "image_urls": image_urls,

                "file_urls": file_urls,

                "geo_places": geo_places

            }

        }

        logger.debug(f"{response} - –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç–≤–µ—Ç")

        if debug_mode:

            response["debug_info"] = {

                "results_count": len(results),

                "query_type": "relational",

                "raw_results": results[:3]

            }

            

        return response

    

    def _apply_dynamic_threshold(

        self,

        results: List[Document],

        scores: List[float],

        deviation: float,

        debug_mode: bool

    ) -> Tuple[List[Document], List[float]]:

        """–§–∏–ª—å—Ç—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—é –æ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å—Ö–æ–∂–µ—Å—Ç–∏"""

        if not results or not scores:

            return results, scores

            

        max_score = max(scores)

        threshold_dynamic = max_score - deviation

        

        filtered_results = []

        filtered_scores = []

        

        for i, score in enumerate(scores):

            if score >= threshold_dynamic:

                filtered_results.append(results[i])

                filtered_scores.append(score)

        

        if debug_mode:

            logger.debug(

                f"–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –ø–æ—Ä–æ–≥: max={max_score:.4f}, "

                f"deviation={deviation}, "

                f"threshold={threshold_dynamic:.4f}, "

                f"–æ—Å—Ç–∞–ª–æ—Å—å {len(filtered_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"

            )

            

        return filtered_results, filtered_scores

    

    def _extract_requested_types(self, modified_query: str) -> Optional[List[str]]:

        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∏–∑ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"""

        if 'type:' not in modified_query:

            return None

            

        parts = modified_query.split('type:')

        type_part = parts[1].strip()

        return [t.strip() for t in type_part.split('|')]



    def _get_search_stores(self, requested_types: Optional[List[str]]) -> List[str]:

        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ö—Ä–∞–Ω–∏–ª–∏—â –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã—Ö —Ç–∏–ø–æ–≤"""

        if not requested_types:

            return list(self.vectorstores.keys())

            

        return [

            t for t in requested_types

            if t in self.vectorstores

        ]

        

    def _search_documents(self, query, search_stores, similarity_threshold, debug_mode):

        """–ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ —É–∫–∞–∑–∞–Ω–Ω—ã—Ö —Ö—Ä–∞–Ω–∏–ª–∏—â–∞—Ö"""

        all_results = []

        all_scores = []

        

        for store_type in search_stores:

            try:

                vectorstore = self.vectorstores[store_type]

                scored_results = vectorstore.similarity_search_with_score(query, k=10)

                

                for doc, score in scored_results:

                    similarity_value = 1 / (1 + score)

                    if similarity_value >= similarity_threshold:

                        all_results.append(doc)

                        all_scores.append(float(similarity_value))

                        

                logger.debug(f"–ù–∞–π–¥–µ–Ω–æ {len(scored_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ {store_type}")

                

            except Exception as e:

                logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ {store_type}: {str(e)}")

                if debug_mode:

                    all_results.append(Document(

                        page_content=f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ {store_type}: {str(e)}",

                        metadata={"type": "–û—à–∏–±–∫–∞", "name": "–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞"}

                    ))

                    all_scores.append(0.0)

        

        return all_results, all_scores 

    
    def get_objects_in_area_by_type(
    self,
    area_geometry: dict,
    object_type: Optional[str] = None,
    object_subtype: Optional[str] = None,
    object_name: Optional[str] = None,
    limit: int = 20
) -> Dict[str, Any]:
        """
        –ü–æ–∏—Å–∫ –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –∑–∞–¥–∞–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ —Ç–∏–ø—É –∏ –∏–º–µ–Ω–∏
        """
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å–ª–æ–∂–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
            results = self.relational_service.get_objects_in_area_by_type(
                area_geometry=area_geometry,
                object_type=object_type,
                object_subtype=object_subtype,
                object_name=object_name,
                limit=limit
            )
            
            if not results:
                # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–Ω—è—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ –ø–æ–∏—Å–∫–∞
                if object_name:
                    message = f"–û–±—ä–µ–∫—Ç '{object_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏"
                elif object_type:
                    subtype_msg = f" –ø–æ–¥—Ç–∏–ø–∞ '{object_subtype}'" if object_subtype else ""
                    message = f"–í —É–∫–∞–∑–∞–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤ —Ç–∏–ø–∞ '{object_type}'{subtype_msg}"
                else:
                    message = "–í —É–∫–∞–∑–∞–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤"
                    
                return {
                    "answer": message,
                    "objects": [],
                    "area_geometry": area_geometry
                }
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            if object_name:
                message = f"–ù–∞–π–¥–µ–Ω –æ–±—ä–µ–∫—Ç '{object_name}' –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏"
            else:
                type_msg = f"—Ç–∏–ø–∞ '{object_type}'" if object_type else "–≤—Å–µ—Ö —Ç–∏–ø–æ–≤"
                subtype_msg = f" (–ø–æ–¥—Ç–∏–ø: {object_subtype})" if object_subtype else ""
                message = f"–ù–∞–π–¥–µ–Ω–æ {len(results)} –æ–±—ä–µ–∫—Ç–æ–≤ {type_msg}{subtype_msg} –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏"
            
            return {
                "answer": message,
                "objects": results,
                "area_geometry": area_geometry
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ —Ç–∏–ø—É –≤ –æ–±–ª–∞—Å—Ç–∏: {str(e)}")
            return {
                "answer": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –æ–±–ª–∞—Å—Ç–∏",
                "objects": [],
                "area_geometry": area_geometry
            }
            
    def search_objects_directly_by_name(
    self,
    object_name: str,
    object_type: Optional[str] = None,
    object_subtype: Optional[str] = None,
    limit: int = 20
) -> Dict[str, Any]:
        """
        –ü—Ä—è–º–æ–π –ø–æ–∏—Å–∫ –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ –∏–º–µ–Ω–∏ –±–µ–∑ –ø—Ä–∏–≤—è–∑–∫–∏ –∫ –æ–±–ª–∞—Å—Ç–∏
        
        Args:
            object_name: –ù–∞–∑–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
            object_type: –¢–∏–ø –æ–±—ä–µ–∫—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            object_subtype: –ü–æ–¥—Ç–∏–ø –æ–±—ä–µ–∫—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –æ–±—ä–µ–∫—Ç–æ–≤
        """
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ –∏–º–µ–Ω–∏
            results = self.relational_service.search_objects_by_name(
                object_name=object_name,
                object_type=object_type,
                object_subtype=object_subtype,
                limit=limit
            )
            
            if not results:
                return {
                    "answer": f"–û–±—ä–µ–∫—Ç '{object_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω",
                    "objects": []
                }
            
            return {
                "answer": f"–ù–∞–π–¥–µ–Ω –æ–±—ä–µ–∫—Ç '{object_name}'",
                "objects": results
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä—è–º–æ–≥–æ –ø–æ–∏—Å–∫–∞ –æ–±—ä–µ–∫—Ç–∞ '{object_name}': {str(e)}")
            return {
                "answer": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –æ–±—ä–µ–∫—Ç–∞ '{object_name}'",
                "objects": []
            }
        
    def get_objects_in_polygon(

    self,

    polygon_geojson: dict,

    buffer_radius_km: float = 0,

    object_type: str = None,

    limit: int = 20

) -> Dict[str, Any]:

        """–ü–æ–∏—Å–∫ –æ–±—ä–µ–∫—Ç–æ–≤ –≤–Ω—É—Ç—Ä–∏ –ø–æ–ª–∏–≥–æ–Ω–∞ –∏ –≤ –±—É—Ñ–µ—Ä–Ω–æ–π –∑–æ–Ω–µ"""

        try:

            results = self.geo_service.get_objects_in_polygon(

                polygon_geojson=polygon_geojson,

                buffer_radius_km=buffer_radius_km,

                object_type=object_type,

                limit=limit

            )

            

            if not results:

                return {

                    "answer": "–í —É–∫–∞–∑–∞–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤",

                    "objects": [],

                    "polygon": polygon_geojson,

                    "biological_objects": ""

                }

            

            formatted_results = []

            type_counts = {}

            biological_objects = []

            

            for obj in results:

                obj_type = obj.get("type", "unknown")

                type_counts[obj_type] = type_counts.get(obj_type, 0) + 1

                

                formatted_obj = {

                    "name": obj["name"],

                    "distance": f"{obj['distance_km']:.1f} –∫–º –æ—Ç —Ü–µ–Ω—Ç—Ä–∞",

                    "type": obj_type,

                    "geojson": obj["geojson"]

                }

                

                if obj_type == "biological_entity":

                    biological_objects.append(obj["name"])

                

                if obj.get("description"):

                    formatted_obj["description"] = obj["description"][:200] + "..." if len(obj["description"]) > 200 else obj["description"]

                

                formatted_results.append(formatted_obj)

            

            total_count = len(results)

            type_summary = ", ".join([f"{count} {type_name}" for type_name, count in type_counts.items()])

            area_desc = "–ø–æ–ª–∏–≥–æ–Ω–∞" if buffer_radius_km == 0 else f"–ø–æ–ª–∏–≥–æ–Ω–∞ + {buffer_radius_km}–∫–º –±—É—Ñ–µ—Ä"

            

            biological_objects_str = ", ".join(biological_objects) if biological_objects else "–±–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–±—ä–µ–∫—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"

            

            answer = f"–ù–∞–π–¥–µ–Ω–æ {total_count} –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –æ–±–ª–∞—Å—Ç–∏ {area_desc} ({type_summary}). –ë–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–±—ä–µ–∫—Ç—ã: {biological_objects_str}"

            

            return {

                "answer": answer,

                "objects": formatted_results,

                "polygon": polygon_geojson,

                "biological_objects": biological_objects_str 

            }

            

        except Exception as e:

            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ –ø–æ–ª–∏–≥–æ–Ω—É: {str(e)}")

            return {

                "answer": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –æ–±–ª–∞—Å—Ç–∏",

                "objects": [],

                "polygon": polygon_geojson,

                "biological_objects": ""

            }

            

    def get_nearby_objects(

    self, 

    latitude: float, 

    longitude: float,

    object_type: str = None,

    radius_km: float = 10,

    species_name: Optional[Union[str, List[str]]] = None 

) -> Dict[str, Any]:

        try:

            # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ GeoService

            start = time.perf_counter()

            results = self.geo_service.get_nearby_objects(

                latitude, 

                longitude,

                object_type=object_type,

                radius_km=radius_km,

                species_name=species_name 

            )

            logger.info(f"Nearby objects search took: {time.perf_counter() - start:.2f}s")

            if not results:

                return {

                    "answer": f"–í —Ä–∞–¥–∏—É—Å–µ {radius_km} –∫–º –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤",

                    "objects": []

                }

            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

            formatted_results = []

            type_counts = {}

            for obj in results:

                # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ç–∏–ø–∞–º

                obj_type = obj.get("type", "unknown")

                type_counts[obj_type] = type_counts.get(obj_type, 0) + 1

                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –æ–±—ä–µ–∫—Ç

                formatted_obj = {

                    "name": obj["name"],

                    "distance": f"{obj['distance_km']:.1f} –∫–º",

                    "type": obj_type,

                    "geojson": obj["geojson"]

                }

                # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ, –µ—Å–ª–∏ –µ—Å—Ç—å

                if obj.get("description"):

                    formatted_obj["description"] = obj["description"][:200] + "..." if len(obj["description"]) > 200 else obj["description"]

                

                formatted_results.append(formatted_obj)

            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ

            total_count = len(results)

            type_summary = ", ".join([f"{count} {type_name}" for type_name, count in type_counts.items()])

            answer = f"–ù–∞–π–¥–µ–Ω–æ {total_count} –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ–±–ª–∏–∑–æ—Å—Ç–∏ ({type_summary})"

            

            return {

                "answer": answer,

                "objects": formatted_results

            }

 

        except Exception as e:

            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –æ–±—ä–µ–∫—Ç–æ–≤: {str(e)}")

            return {

                "answer": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –±–ª–∏–∂–∞–π—à–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤",

                "objects": []

            }

            

    def _format_response(

    self,

    results,

    requested_types,

    scores,

    debug_mode,

    user_id=None, 

    error=None

):

        answer, urls = response_formatter.format_response(

        results,

        requested_types,

        scores,

        debug_mode,

        user_id=user_id 

        )

          

        response = {

            "answer": answer,

            "multi_url": {

                "image_urls": urls.get("images", []),

                "file_urls": urls.get("files", []),

                "geo_places": urls.get("geo_places", [])

            }

        }

        

        if debug_mode:

            response["debug_info"] = {

                "results_count": len(results),

                "error": error

            }

            

        return response

    

    def _build_empty_response(self, message, debug_mode):

        response = {

            "answer": f"–ò–∑–≤–∏–Ω–∏—Ç–µ, {message.lower()}",

            "multi_url": {

                "image_urls": [],

                "file_urls": [],

                "geo_places": []

            }

        }

        if debug_mode:

            response["debug_info"] = {"message": message}

        return response

    

    def _build_error_response(self, error, debug_mode):

        response = {

            "answer": "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞",

            "multi_url": {

                "image_urls": [],

                "file_urls": [],

                "geo_places": []

            }

        }

        if debug_mode:

            response["debug_info"] = {"error": error}

        return response
